<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js ayu">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>DataFrame - Polars - Python Reference Guide</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="../../../favicon.svg">
        
        
        <link rel="shortcut icon" href="../../../favicon.png">
        
        <link rel="stylesheet" href="../../../css/variables.css">
        <link rel="stylesheet" href="../../../css/general.css">
        <link rel="stylesheet" href="../../../css/chrome.css">
        
        <link rel="stylesheet" href="../../../css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="../../../FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="../../../fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../../highlight.css">
        <link rel="stylesheet" href="../../../tomorrow-night.css">
        <link rel="stylesheet" href="../../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
        <link rel="stylesheet" href="../../../theme/css/style.css">
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "ayu";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item "><a href="../../../polars.html">polars</a></li><li class="chapter-item "><a href="../../../polars/datatypes.html">datatypes</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/datatypes/DataType.html">DataType</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Int8.html">Int8</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Int16.html">Int16</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Int32.html">Int32</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Int64.html">Int64</a></li><li class="chapter-item "><a href="../../../polars/datatypes/UInt8.html">UInt8</a></li><li class="chapter-item "><a href="../../../polars/datatypes/UInt16.html">UInt16</a></li><li class="chapter-item "><a href="../../../polars/datatypes/UInt32.html">UInt32</a></li><li class="chapter-item "><a href="../../../polars/datatypes/UInt64.html">UInt64</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Float32.html">Float32</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Float64.html">Float64</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Boolean.html">Boolean</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Utf8.html">Utf8</a></li><li class="chapter-item "><a href="../../../polars/datatypes/List.html">List</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Date32.html">Date32</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Date64.html">Date64</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Time32Millisecond.html">Time32Millisecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Time32Second.html">Time32Second</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Time64Nanosecond.html">Time64Nanosecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Time64Microsecond.html">Time64Microsecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/DurationNanosecond.html">DurationNanosecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/DurationMicrosecond.html">DurationMicrosecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/DurationMillisecond.html">DurationMillisecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/DurationSecond.html">DurationSecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/TimestampNanosecond.html">TimestampNanosecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/TimestampMicrosecond.html">TimestampMicrosecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/TimestampMillisecond.html">TimestampMillisecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/TimestampSecond.html">TimestampSecond</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Object.html">Object</a></li><li class="chapter-item "><a href="../../../polars/datatypes/Categorical.html">Categorical</a></li></ol></li><li class="chapter-item expanded "><a href="../../../polars/eager.html">eager</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../polars/eager/frame.html">frame</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../polars/eager/frame/DataFrame.html" class="active">DataFrame</a></li><li class="chapter-item "><a href="../../../polars/eager/frame/GroupBy.html">GroupBy</a></li><li class="chapter-item "><a href="../../../polars/eager/frame/PivotOps.html">PivotOps</a></li><li class="chapter-item "><a href="../../../polars/eager/frame/GBSelection.html">GBSelection</a></li></ol></li><li class="chapter-item "><a href="../../../polars/eager/series.html">series</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/eager/series/Series.html">Series</a></li><li class="chapter-item "><a href="../../../polars/eager/series/StringNameSpace.html">StringNameSpace</a></li><li class="chapter-item "><a href="../../../polars/eager/series/DateTimeNameSpace.html">DateTimeNameSpace</a></li><li class="chapter-item "><a href="../../../polars/eager/series/SeriesIter.html">SeriesIter</a></li></ol></li></ol></li><li class="chapter-item "><a href="../../../polars/functions.html">functions</a></li><li class="chapter-item "><a href="../../../polars/io.html">io</a></li><li class="chapter-item "><a href="../../../polars/lazy.html">lazy</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/lazy/expr.html">expr</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/lazy/expr/Expr.html">Expr</a></li><li class="chapter-item "><a href="../../../polars/lazy/expr/ExprStringNameSpace.html">ExprStringNameSpace</a></li><li class="chapter-item "><a href="../../../polars/lazy/expr/ExprDateTimeNameSpace.html">ExprDateTimeNameSpace</a></li></ol></li><li class="chapter-item "><a href="../../../polars/lazy/frame.html">frame</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/lazy/frame/LazyFrame.html">LazyFrame</a></li><li class="chapter-item "><a href="../../../polars/lazy/frame/LazyGroupBy.html">LazyGroupBy</a></li></ol></li><li class="chapter-item "><a href="../../../polars/lazy/functions.html">functions</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/lazy/functions/UDF.html">UDF</a></li></ol></li><li class="chapter-item "><a href="../../../polars/lazy/whenthen.html">whenthen</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/lazy/whenthen/WhenThenThen.html">WhenThenThen</a></li><li class="chapter-item "><a href="../../../polars/lazy/whenthen/WhenThen.html">WhenThen</a></li><li class="chapter-item "><a href="../../../polars/lazy/whenthen/When.html">When</a></li></ol></li></ol></li><li class="chapter-item "><a href="../../../polars/string_cache.html">string_cache</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../../../polars/string_cache/StringCache.html">StringCache</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu (default)</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Polars - Python Reference Guide</h1>

                    <div class="right-buttons">
                        
                        <a href="../../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        

                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="polarseagerframedataframe"><a class="header" href="#polarseagerframedataframe"><code>polars.eager.frame.DataFrame</code></a></h1>
<p>A DataFrame is a two-dimensional data structure that represents data as a table
with rows and columns.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>data</code> [<code>dict, Sequence, ndarray, Series, or pandas.DataFrame</code>]: Two-dimensional data in various forms. dict may contain Series or Sequences.
Sequence may contain Series or other Sequences.</li>
<li><code>columns</code> [<code>Sequence of str, default None</code>]: Column labels to use for resulting DataFrame. If specified, overrides any
labels already present in the data. Must match data dimensions.
orientation : {'column', 'row'}, default None
Whether to interpret two-dimensional data as columns or as rows. If None,
the orientation is infered by matching the columns and data dimensions. If this
does not yield conclusive results, 'column' orientation is used.</li>
<li><code>nullable</code> [<code>bool, default True</code>]: If your data does not contain null values, set to False to speed up
DataFrame creation.</li>
</ul>
<p><strong>Examples:</strong></p>
<p>Constructing a DataFrame from a dictionary:</p>
<pre><code class="language-python">&gt;&gt;&gt; data = {'a': [1, 2], 'b': [3, 4]}
&gt;&gt;&gt; df = pl.DataFrame(data)
&gt;&gt;&gt; df
shape: (2, 2)
╭─────┬─────╮
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 3   │
├╌╌╌╌╌┼╌╌╌╌╌┤
│ 2   ┆ 4   │
╰─────┴─────╯
</code></pre>
<p>Notice that the dtype is automatically inferred as a polars Int64:</p>
<pre><code class="language-python">&gt;&gt;&gt; df.dtypes
[&lt;class 'polars.datatypes.Int64'&gt;, &lt;class 'polars.datatypes.Int64'&gt;]
</code></pre>
<p>In order to specify dtypes for your columns, initialize the DataFrame with a list
of Series instead:</p>
<pre><code class="language-python">&gt;&gt;&gt; data = [pl.Series('col1', [1, 2], dtype=pl.Float32),
...         pl.Series('col2', [3, 4], dtype=pl.Int64)]
&gt;&gt;&gt; df2 = pl.DataFrame(series)
&gt;&gt;&gt; df2
shape: (2, 2)
╭──────┬──────╮
│ col1 ┆ col2 │
│ ---  ┆ ---  │
│ f32  ┆ i64  │
╞══════╪══════╡
│ 1    ┆ 3    │
├╌╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 2    ┆ 4    │
╰──────┴──────╯
</code></pre>
<p>Constructing a DataFrame from a numpy ndarray, specifying column names:</p>
<pre><code class="language-python">&gt;&gt;&gt; data = np.array([(1, 2), (3, 4)])
&gt;&gt;&gt; df3 = pl.DataFrame(data, columns=['a', 'b'], orientation='column')
&gt;&gt;&gt; df3
shape: (2, 2)
╭─────┬─────╮
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 3   │
├╌╌╌╌╌┼╌╌╌╌╌┤
│ 2   ┆ 4   │
╰─────┴─────╯
</code></pre>
<p>Constructing a DataFrame from a list of lists, row orientation inferred:</p>
<pre><code class="language-python">&gt;&gt;&gt; data = [[1, 2, 3], [4, 5, 6]]
&gt;&gt;&gt; df4 = pl.DataFrame(data, columns=['a', 'b', 'c'])
&gt;&gt;&gt; df4
shape: (2, 3)
╭─────┬─────┬─────╮
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ 1   ┆ 2   ┆ 3   │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 4   ┆ 5   ┆ 6   │
╰─────┴─────┴─────╯
</code></pre>
<p><strong>Methods:</strong></p>
<ul>
<li><a href="#polarseagerframedataframefrom_rows"><code>from_rows()</code></a></li>
<li><a href="#polarseagerframedataframeread_csv"><code>read_csv()</code></a></li>
<li><a href="#polarseagerframedataframeread_parquet"><code>read_parquet()</code></a></li>
<li><a href="#polarseagerframedataframeread_ipc"><code>read_ipc()</code></a></li>
<li><a href="#polarseagerframedataframeread_json"><code>read_json()</code></a></li>
<li><a href="#polarseagerframedataframefrom_arrow"><code>from_arrow()</code></a></li>
<li><a href="#polarseagerframedataframeto_arrow"><code>to_arrow()</code></a></li>
<li><a href="#polarseagerframedataframeto_json"><code>to_json()</code></a></li>
<li><a href="#polarseagerframedataframeto_pandas"><code>to_pandas()</code></a></li>
<li><a href="#polarseagerframedataframeto_csv"><code>to_csv()</code></a></li>
<li><a href="#polarseagerframedataframeto_ipc"><code>to_ipc()</code></a></li>
<li><a href="#polarseagerframedataframeto_parquet"><code>to_parquet()</code></a></li>
<li><a href="#polarseagerframedataframeto_numpy"><code>to_numpy()</code></a></li>
<li><a href="#polarseagerframedataframefind_idx_by_name"><code>find_idx_by_name()</code></a></li>
<li><a href="#polarseagerframedataframerename"><code>rename()</code></a></li>
<li><a href="#polarseagerframedataframeinsert_at_idx"><code>insert_at_idx()</code></a></li>
<li><a href="#polarseagerframedataframefilter"><code>filter()</code></a></li>
<li><a href="#polarseagerframedataframeshape"><code>shape()</code></a></li>
<li><a href="#polarseagerframedataframeheight"><code>height()</code></a></li>
<li><a href="#polarseagerframedataframewidth"><code>width()</code></a></li>
<li><a href="#polarseagerframedataframecolumns"><code>columns()</code></a></li>
<li><a href="#polarseagerframedataframedtypes"><code>dtypes()</code></a></li>
<li><a href="#polarseagerframedataframedescribe"><code>describe()</code></a></li>
<li><a href="#polarseagerframedataframedescribedescribe_cast"><code>describe_cast()</code></a></li>
<li><a href="#polarseagerframedataframereplace_at_idx"><code>replace_at_idx()</code></a></li>
<li><a href="#polarseagerframedataframesort"><code>sort()</code></a></li>
<li><a href="#polarseagerframedataframeframe_equal"><code>frame_equal()</code></a></li>
<li><a href="#polarseagerframedataframereplace"><code>replace()</code></a></li>
<li><a href="#polarseagerframedataframeslice"><code>slice()</code></a></li>
<li><a href="#polarseagerframedataframelimit"><code>limit()</code></a></li>
<li><a href="#polarseagerframedataframehead"><code>head()</code></a></li>
<li><a href="#polarseagerframedataframetail"><code>tail()</code></a></li>
<li><a href="#polarseagerframedataframedrop_nulls"><code>drop_nulls()</code></a></li>
<li><a href="#polarseagerframedataframepipe"><code>pipe()</code></a></li>
<li><a href="#polarseagerframedataframegroupby"><code>groupby()</code></a></li>
<li><a href="#polarseagerframedataframedownsample"><code>downsample()</code></a></li>
<li><a href="#polarseagerframedataframejoin"><code>join()</code></a></li>
<li><a href="#polarseagerframedataframeapply"><code>apply()</code></a></li>
<li><a href="#polarseagerframedataframewith_column"><code>with_column()</code></a></li>
<li><a href="#polarseagerframedataframehstack"><code>hstack()</code></a></li>
<li><a href="#polarseagerframedataframevstack"><code>vstack()</code></a></li>
<li><a href="#polarseagerframedataframedrop"><code>drop()</code></a></li>
<li><a href="#polarseagerframedataframedrop_in_place"><code>drop_in_place()</code></a></li>
<li><a href="#polarseagerframedataframeselect_at_idx"><code>select_at_idx()</code></a></li>
<li><a href="#polarseagerframedataframeclone"><code>clone()</code></a></li>
<li><a href="#polarseagerframedataframeget_columns"><code>get_columns()</code></a></li>
<li><a href="#polarseagerframedataframefill_none"><code>fill_none()</code></a></li>
<li><a href="#polarseagerframedataframeexplode"><code>explode()</code></a></li>
<li><a href="#polarseagerframedataframemelt"><code>melt()</code></a></li>
<li><a href="#polarseagerframedataframeshift"><code>shift()</code></a></li>
<li><a href="#polarseagerframedataframeshift_and_fill"><code>shift_and_fill()</code></a></li>
<li><a href="#polarseagerframedataframeis_duplicated"><code>is_duplicated()</code></a></li>
<li><a href="#polarseagerframedataframeis_unique"><code>is_unique()</code></a></li>
<li><a href="#polarseagerframedataframelazy"><code>lazy()</code></a></li>
<li><a href="#polarseagerframedataframeselect"><code>select()</code></a></li>
<li><a href="#polarseagerframedataframewith_columns"><code>with_columns()</code></a></li>
<li><a href="#polarseagerframedataframen_chunks"><code>n_chunks()</code></a></li>
<li><a href="#polarseagerframedataframemax"><code>max()</code></a></li>
<li><a href="#polarseagerframedataframemin"><code>min()</code></a></li>
<li><a href="#polarseagerframedataframesum"><code>sum()</code></a></li>
<li><a href="#polarseagerframedataframemean"><code>mean()</code></a></li>
<li><a href="#polarseagerframedataframestd"><code>std()</code></a></li>
<li><a href="#polarseagerframedataframevar"><code>var()</code></a></li>
<li><a href="#polarseagerframedataframemedian"><code>median()</code></a></li>
<li><a href="#polarseagerframedataframequantile"><code>quantile()</code></a></li>
<li><a href="#polarseagerframedataframeto_dummies"><code>to_dummies()</code></a></li>
<li><a href="#polarseagerframedataframedrop_duplicates"><code>drop_duplicates()</code></a></li>
<li><a href="#polarseagerframedataframerechunk"><code>rechunk()</code></a></li>
<li><a href="#polarseagerframedataframenull_count"><code>null_count()</code></a></li>
<li><a href="#polarseagerframedataframesample"><code>sample()</code></a></li>
<li><a href="#polarseagerframedataframefold"><code>fold()</code></a></li>
<li><a href="#polarseagerframedataframerow"><code>row()</code></a></li>
<li><a href="#polarseagerframedataframerows"><code>rows()</code></a></li>
<li><a href="#polarseagerframedataframeshrink_to_fit"><code>shrink_to_fit()</code></a></li>
<li><a href="#polarseagerframedataframehash_rows"><code>hash_rows()</code></a></li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">class DataFrame:
    &quot;&quot;&quot;
    A DataFrame is a two-dimensional data structure that represents data as a table
    with rows and columns.

    Parameters
    ----------
    data : dict, Sequence, ndarray, Series, or pandas.DataFrame
        Two-dimensional data in various forms. dict may contain Series or Sequences.
        Sequence may contain Series or other Sequences.
    columns : Sequence of str, default None
        Column labels to use for resulting DataFrame. If specified, overrides any
        labels already present in the data. Must match data dimensions.
    orientation : {'column', 'row'}, default None
        Whether to interpret two-dimensional data as columns or as rows. If None,
        the orientation is infered by matching the columns and data dimensions. If this
        does not yield conclusive results, 'column' orientation is used.
    nullable : bool, default True
        If your data does not contain null values, set to False to speed up
        DataFrame creation.

    Examples
    --------
    Constructing a DataFrame from a dictionary:

    ```python
    &gt;&gt;&gt; data = {'a': [1, 2], 'b': [3, 4]}
    &gt;&gt;&gt; df = pl.DataFrame(data)
    &gt;&gt;&gt; df
    shape: (2, 2)
    ╭─────┬─────╮
    │ a   ┆ b   │
    │ --- ┆ --- │
    │ i64 ┆ i64 │
    ╞═════╪═════╡
    │ 1   ┆ 3   │
    ├╌╌╌╌╌┼╌╌╌╌╌┤
    │ 2   ┆ 4   │
    ╰─────┴─────╯
    ```

    Notice that the dtype is automatically inferred as a polars Int64:

    ```python
    &gt;&gt;&gt; df.dtypes
    [&lt;class 'polars.datatypes.Int64'&gt;, &lt;class 'polars.datatypes.Int64'&gt;]
    ```

    In order to specify dtypes for your columns, initialize the DataFrame with a list
    of Series instead:

    ```python
    &gt;&gt;&gt; data = [pl.Series('col1', [1, 2], dtype=pl.Float32),
    ...         pl.Series('col2', [3, 4], dtype=pl.Int64)]
    &gt;&gt;&gt; df2 = pl.DataFrame(series)
    &gt;&gt;&gt; df2
    shape: (2, 2)
    ╭──────┬──────╮
    │ col1 ┆ col2 │
    │ ---  ┆ ---  │
    │ f32  ┆ i64  │
    ╞══════╪══════╡
    │ 1    ┆ 3    │
    ├╌╌╌╌╌╌┼╌╌╌╌╌╌┤
    │ 2    ┆ 4    │
    ╰──────┴──────╯
    ```

    Constructing a DataFrame from a numpy ndarray, specifying column names:

    ```python
    &gt;&gt;&gt; data = np.array([(1, 2), (3, 4)])
    &gt;&gt;&gt; df3 = pl.DataFrame(data, columns=['a', 'b'], orientation='column')
    &gt;&gt;&gt; df3
    shape: (2, 2)
    ╭─────┬─────╮
    │ a   ┆ b   │
    │ --- ┆ --- │
    │ i64 ┆ i64 │
    ╞═════╪═════╡
    │ 1   ┆ 3   │
    ├╌╌╌╌╌┼╌╌╌╌╌┤
    │ 2   ┆ 4   │
    ╰─────┴─────╯
    ```

    Constructing a DataFrame from a list of lists, row orientation inferred:

    ```python
    &gt;&gt;&gt; data = [[1, 2, 3], [4, 5, 6]]
    &gt;&gt;&gt; df4 = pl.DataFrame(data, columns=['a', 'b', 'c'])
    &gt;&gt;&gt; df4
    shape: (2, 3)
    ╭─────┬─────┬─────╮
    │ a   ┆ b   ┆ c   │
    │ --- ┆ --- ┆ --- │
    │ i64 ┆ i64 ┆ i64 │
    ╞═════╪═════╪═════╡
    │ 1   ┆ 2   ┆ 3   │
    ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
    │ 4   ┆ 5   ┆ 6   │
    ╰─────┴─────┴─────╯
    ```
    &quot;&quot;&quot;

    def __init__(
        self,
        data: Optional[
            Union[
                Dict[str, Sequence[Any]],
                Sequence[Any],
                np.ndarray,
                &quot;pd.DataFrame&quot;,
                &quot;pl.Series&quot;,
            ]
        ] = None,
        columns: Optional[Sequence[str]] = None,
        orientation: Optional[str] = None,
        nullable: bool = True,
    ):
        # Handle positional arguments for old constructor
        if isinstance(columns, bool):
            warnings.warn(
                &quot;Specifying nullable as a positional argument is deprecated. &quot;
                &quot;Use a keyword argument to silence this warning.&quot;,
                DeprecationWarning,
                stacklevel=2,
            )
            nullable = columns
            columns = None

        # Parse data into a list of Series
        data_series: tp.List[&quot;pl.Series&quot;]

        if data is None:
            data_series = []

        elif isinstance(data, dict):
            data_series = [
                pl.Series(k, v, nullable=nullable).inner() for k, v in data.items()
            ]

        elif isinstance(data, np.ndarray):
            shape = data.shape

            if shape == (0,):
                data_series = []

            elif len(shape) == 1:
                s = pl.Series(&quot;column_0&quot;, data, nullable=False).inner()
                data_series = [s]

            elif len(shape) == 2:
                # Infer orientation
                if orientation is None:
                    warnings.warn(
                        &quot;Default orientation for constructing DataFrame from numpy &quot;
                        'array will change from &quot;row&quot; to &quot;column&quot; in a future version. '
                        &quot;Specify orientation explicitly to silence this warning.&quot;,
                        DeprecationWarning,
                        stacklevel=2,
                    )
                    orientation = &quot;row&quot;
                # Exchange if-block above for block below when removing warning
                # if orientation is None and columns is not None:
                #     orientation = &quot;column&quot; if len(columns) == shape[0] else &quot;row&quot;

                if orientation == &quot;row&quot;:
                    data_series = [
                        pl.Series(f&quot;column_{i}&quot;, data[:, i], nullable=False).inner()
                        for i in range(shape[1])
                    ]
                else:
                    data_series = [
                        pl.Series(f&quot;column_{i}&quot;, data[i], nullable=False).inner()
                        for i in range(shape[0])
                    ]

            else:
                raise ValueError(&quot;A numpy array should have more than two dimensions.&quot;)

        elif isinstance(data, Sequence) and not isinstance(data, str):
            if len(data) == 0:
                data_series = []

            elif isinstance(data[0], pl.Series):
                data_series = []
                for i, s in enumerate(data):
                    if not s.name:  # TODO: Replace by `if s.name is None` once allowed
                        s.rename(f&quot;column_{i}&quot;, in_place=True)
                    data_series.append(s.inner())

            elif isinstance(data[0], Sequence) and not isinstance(data[0], str):
                # Infer orientation
                if orientation is None and columns is not None:
                    orientation = &quot;column&quot; if len(columns) == len(data) else &quot;row&quot;

                if orientation == &quot;row&quot;:
                    self._df = PyDataFrame.read_rows(data)
                    if columns is not None:
                        self.columns = list(columns)
                    return
                else:
                    data_series = [
                        pl.Series(f&quot;column_{i}&quot;, data[i], nullable=nullable).inner()
                        for i in range(len(data))
                    ]

            else:
                s = pl.Series(&quot;column_0&quot;, data, nullable=nullable).inner()
                data_series = [s]

        elif isinstance(data, pl.Series):
            data_series = [data.inner()]

        elif _PANDAS_AVAILABLE and isinstance(data, pd.DataFrame):
            if nullable:
                data_series = [
                    pl.Series(str(col), data[col].to_list(), nullable=True).inner()
                    for col in data.columns
                ]
            else:
                data_series = [
                    pl.Series(str(col), data[col].values, nullable=False).inner()
                    for col in data.columns
                ]

        else:
            raise ValueError(&quot;DataFrame constructor not called properly.&quot;)

        # Handle the resulting list of Series
        if not data_series and columns is not None:
            for c in columns:
                data_series.append(pl.Series(c, [], nullable=nullable).inner())

        self._df = PyDataFrame(data_series)

        if columns is not None:
            self.columns = list(columns)

    @staticmethod
    def _from_pydf(df: &quot;PyDataFrame&quot;) -&gt; &quot;DataFrame&quot;:
        self = DataFrame.__new__(DataFrame)
        self._df = df
        return self

    @staticmethod
    def from_rows(
        rows: Sequence[Sequence[Any]],
        column_names: Optional[Sequence[str]] = None,
        column_name_mapping: Optional[Dict[int, str]] = None,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Create a DataFrame from rows. This should only be used as a last resort, as this is more expensive than
        creating from columnar data.

        Parameters
        ----------
        rows
            rows.
        column_names
            column names to use for the DataFrame.
        column_name_mapping
            map column index to a new name:
            Example:
            ```python
                column_mapping: {0: &quot;first_column, 3: &quot;fourth column&quot;}
            ```
        &quot;&quot;&quot;
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_rows(rows)
        if column_names is not None:
            self.columns = list(column_names)
        if column_name_mapping is not None:
            for i, name in column_name_mapping.items():
                s = self[:, i]
                s.rename(name, in_place=True)
                self.replace_at_idx(i, s)
        return self

    @staticmethod
    def read_csv(
        file: Union[str, BinaryIO, bytes],
        infer_schema_length: int = 100,
        batch_size: int = 64,
        has_headers: bool = True,
        ignore_errors: bool = False,
        stop_after_n_rows: Optional[int] = None,
        skip_rows: int = 0,
        projection: Optional[tp.List[int]] = None,
        sep: str = &quot;,&quot;,
        columns: Optional[tp.List[str]] = None,
        rechunk: bool = True,
        encoding: str = &quot;utf8&quot;,
        n_threads: Optional[int] = None,
        dtype: Optional[Dict[str, Type[DataType]]] = None,
        low_memory: bool = False,
        comment_char: Optional[str] = None,
        null_values: Optional[Union[str, tp.List[str], Dict[str, str]]] = None,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read a CSV file into a Dataframe.

        Parameters
        ---
        file
            Path to a file or a file like object. Any valid filepath can be used. Example: `file.csv`.
        infer_schema_length
            Maximum number of lines to read to infer schema.
        batch_size
            Number of lines to read into the buffer at once. Modify this to change performance.
        has_headers
            Indicate if first row of dataset is header or not. If set to False first row will be set to `column_x`,
            `x` being an enumeration over every column in the dataset.
        ignore_errors
            Try to keep reading lines if some lines yield errors.
        stop_after_n_rows
            After n rows are read from the CSV, it stops reading.
            During multi-threaded parsing, an upper bound of `n` rows
            cannot be guaranteed.
        skip_rows
            Start reading after `skip_rows`.
        projection
            Indexes of columns to select. Note that column indexes count from zero.
        sep
            Character to use as delimiter in the file.
        columns
            Columns to project/ select.
        rechunk
            Make sure that all columns are contiguous in memory by aggregating the chunks into a single array.
        encoding
            Allowed encodings: `utf8`, `utf8-lossy`. Lossy means that invalid utf8 values are replaced with `�` character.
        n_threads
            Number of threads to use in csv parsing. Defaults to the number of physical cpu's of your system.
        dtype
            Overwrite the dtypes during inference.
        low_memory
            Reduce memory usage in expense of performance.
        comment_char
            character that indicates the start of a comment line, for instance '#'.
        null_values
            Values to interpret as null values. You can provide a:

            - str -&gt; all values encountered equal to this string will be null
            - tp.List[str] -&gt; A null value per column.
            - Dict[str, str] -&gt; A dictionary that maps column name to a null value string.

        Example
        ---
        ```python
        dataframe = pl.read_csv('file.csv', sep=';', stop_after_n_rows=25)
        ```

        Returns
        ---
        DataFrame
        &quot;&quot;&quot;
        self = DataFrame.__new__(DataFrame)

        path: Optional[str]
        if isinstance(file, str):
            path = file
        else:
            path = None
            if isinstance(file, BytesIO):
                file = file.getvalue()
            if isinstance(file, StringIO):
                file = file.getvalue().encode()

        dtype_list: Optional[tp.List[Tuple[str, Type[DataType]]]] = None
        if dtype is not None:
            dtype_list = []
            for k, v in dtype.items():
                dtype_list.append((k, pytype_to_polars_type(v)))

        processed_null_values = _process_null_values(null_values)

        self._df = PyDataFrame.read_csv(
            file,
            infer_schema_length,
            batch_size,
            has_headers,
            ignore_errors,
            stop_after_n_rows,
            skip_rows,
            projection,
            sep,
            rechunk,
            columns,
            encoding,
            n_threads,
            path,
            dtype_list,
            low_memory,
            comment_char,
            processed_null_values,
        )
        return self

    @staticmethod
    def read_parquet(
        file: Union[str, BinaryIO],
        stop_after_n_rows: Optional[int] = None,
        use_pyarrow: bool = False,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read into a DataFrame from a parquet file.

        Parameters
        ---
        file
            Path to a file or a file like object. Any valid filepath can be used.
        stop_after_n_rows
            Only read specified number of rows of the dataset. After `n` stops reading.
        use_pyarrow
            Use pyarrow instead of the rust native parquet reader. The pyarrow reader is more stable.
        &quot;&quot;&quot;
        if use_pyarrow:
            if stop_after_n_rows:
                raise ValueError(
                    &quot;stop_after_n_rows can not be used with 'use_pyarrow==True'.&quot;
                )
            tbl = pa.parquet.read_table(file)
            return DataFrame.from_arrow(tbl)
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_parquet(file, stop_after_n_rows)
        return self

    @staticmethod
    def read_ipc(file: Union[str, BinaryIO], use_pyarrow: bool = True) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read into a DataFrame from Arrow IPC stream format. This is also called the feather format.

        Parameters
        ----------
        file
            Path to a file or a file like object.
        use_pyarrow
            Use pyarrow or rust arrow backend.

        Returns
        -------
        DataFrame
        &quot;&quot;&quot;
        if use_pyarrow:
            tbl = pa.feather.read_table(file)
            return DataFrame.from_arrow(tbl)

        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_ipc(file)
        return self

    @staticmethod
    def read_json(file: Union[str, BytesIO]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read into a DataFrame from JSON format.

        Parameters
        ----------
        file
            Path to a file or a file like object.
        &quot;&quot;&quot;
        if not isinstance(file, str):
            file = file.read().decode(&quot;utf8&quot;)
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_json(file)
        return self

    @staticmethod
    def from_arrow(table: pa.Table, rechunk: bool = True) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Create DataFrame from arrow Table.
        Most will be zero copy. Types that are not supported by Polars may be cast to a closest
        supported type.

        Parameters
        ----------
        table
            Arrow Table.
        rechunk
            Make sure that all data is contiguous.
        &quot;&quot;&quot;
        data = {}
        for i, column in enumerate(table):
            # extract the name before casting
            if column._name is None:
                name = f&quot;column_{i}&quot;
            else:
                name = column._name

            column = coerce_arrow(column)
            data[name] = column

        table = pa.table(data)
        batches = table.to_batches()
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.from_arrow_record_batches(batches)
        if rechunk:
            return self.rechunk()
        return self

    def to_arrow(self) -&gt; pa.Table:
        &quot;&quot;&quot;
        Collect the underlying arrow arrays in an Arrow Table.
        This operation is mostly zero copy.

        Data types that do copy:
            - CategoricalType
        &quot;&quot;&quot;
        record_batches = self._df.to_arrow()
        return pa.Table.from_batches(record_batches)

    def to_json(
        self,
        file: Optional[Union[BytesIO, str, Path]] = None,
        pretty: bool = False,
        to_string: bool = False,
    ) -&gt; Optional[str]:
        &quot;&quot;&quot;
        Serialize to JSON representation.

        Parameters
        ----------
        file
            Write to this file instead of returning an string.
        pretty
            Pretty serialize json.
        to_string
            Ignore file argument and return a string.
        &quot;&quot;&quot;
        if to_string:
            file = BytesIO()
            self._df.to_json(file, pretty)
            file.seek(0)
            return file.read().decode(&quot;utf8&quot;)
        else:
            self._df.to_json(file, pretty)
            return None

    def to_pandas(
        self, *args: Any, date_as_object: bool = False, **kwargs: Any
    ) -&gt; &quot;pd.DataFrame&quot;:  # noqa: F821
        &quot;&quot;&quot;
        Cast to a Pandas DataFrame. This requires that Pandas is installed.
        This operation clones data.

        Parameters
        ----------
        args
            Arguments will be sent to pyarrow.Table.to_pandas.
        date_as_object
            Cast dates to objects. If False, convert to datetime64[ns] dtype.
        kwargs
            Arguments will be sent to pyarrow.Table.to_pandas.

        Example
        ---
        ```python
        &gt;&gt;&gt; import pandas
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6, 7, 8],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; pandas_df = dataframe.to_pandas()
        &gt;&gt;&gt; type(pandas_df)
        pandas.core.frame.DataFrame
        ```
        &quot;&quot;&quot;
        return self.to_arrow().to_pandas(*args, date_as_object=date_as_object, **kwargs)

    def to_csv(
        self,
        file: Optional[Union[TextIO, str, Path]] = None,
        has_headers: bool = True,
        delimiter: str = &quot;,&quot;,
    ) -&gt; Optional[str]:
        &quot;&quot;&quot;
        Write Dataframe to comma-separated values file (csv).

        Parameters
        ---
        file
            File path to which the file should be written.
        has_headers
            Whether or not to include header in the CSV output.
        delimiter
            Separate CSV fields with this symbol.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3, 4, 5],
            &quot;bar&quot;: [6, 7, 8, 9, 10],
            &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
            })
        &gt;&gt;&gt; dataframe.to_csv('new_file.csv', sep=',')
        ```
        &quot;&quot;&quot;
        if file is None:
            buffer = BytesIO()
            self._df.to_csv(buffer, has_headers, ord(delimiter))
            return str(buffer.getvalue(), encoding=&quot;utf-8&quot;)

        if isinstance(file, Path):
            file = str(file)

        self._df.to_csv(file, has_headers, ord(delimiter))
        return None

    def to_ipc(self, file: Union[BinaryIO, str, Path]) -&gt; None:
        &quot;&quot;&quot;
        Write to Arrow IPC binary stream, or a feather file.

        Parameters
        ----------
        file
            File path to which the file should be written.
        &quot;&quot;&quot;
        if isinstance(file, Path):
            file = str(file)

        self._df.to_ipc(file)

    def to_parquet(
        self,
        file: Union[str, Path],
        compression: str = &quot;snappy&quot;,
        use_pyarrow: bool = True,
        **kwargs: Any,
    ) -&gt; None:
        &quot;&quot;&quot;
        Write the DataFrame disk in parquet format.

        Parameters
        ----------
        file
            File path to which the file should be written.
        compression
            Compression method (only supported if `use_pyarrow`).
        use_pyarrow
            Use C++ parquet implementation vs rust parquet implementation.
            At the moment C++ supports more features.

        **kwargs are passed to pyarrow.parquet.write_table
        &quot;&quot;&quot;
        if isinstance(file, Path):
            file = str(file)

        if use_pyarrow:
            tbl = self.to_arrow()

            data = {}

            for i, column in enumerate(tbl):
                # extract the name before casting
                if column._name is None:
                    name = f&quot;column_{i}&quot;
                else:
                    name = column._name

                # parquet casts date64 to date32 for some reason
                if column.type == pa.date64():
                    column = pa.compute.cast(column, pa.timestamp(&quot;ms&quot;, None))
                data[name] = column
            tbl = pa.table(data)

            pa.parquet.write_table(
                table=tbl, where=file, compression=compression, **kwargs
            )
        else:
            self._df.to_parquet(file)

    def to_numpy(self) -&gt; np.ndarray:
        &quot;&quot;&quot;
        Convert DataFrame to a 2d numpy array.
        This operation clones data.

        Example
        ---
        ```python
        &gt;&gt;&gt; import pandas
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6, 7, 8],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; numpy_array = dataframe.to_numpy()
        &gt;&gt;&gt; type(numpy_array)
        numpy.ndarray
        ```
        &quot;&quot;&quot;
        return np.vstack(
            [self.select_at_idx(i).to_numpy() for i in range(self.width)]
        ).T

    def __mul__(self, other: Any) -&gt; &quot;DataFrame&quot;:
        other = _prepare_other_arg(other)
        return wrap_df(self._df.mul(other._s))

    def __truediv__(self, other: Any) -&gt; &quot;DataFrame&quot;:
        other = _prepare_other_arg(other)
        return wrap_df(self._df.div(other._s))

    def __add__(self, other: Any) -&gt; &quot;DataFrame&quot;:
        other = _prepare_other_arg(other)
        return wrap_df(self._df.add(other._s))

    def __sub__(self, other: Any) -&gt; &quot;DataFrame&quot;:
        other = _prepare_other_arg(other)
        return wrap_df(self._df.sub(other._s))

    def __str__(self) -&gt; str:
        return self._df.as_str()

    def __repr__(self) -&gt; str:
        return self.__str__()

    def __getattr__(self, item: Any) -&gt; &quot;PySeries&quot;:
        &quot;&quot;&quot;
        Access columns as attribute.
        &quot;&quot;&quot;
        try:
            return pl.eager.series.wrap_s(self._df.column(item))
        except RuntimeError:
            raise AttributeError(f&quot;{item} not found&quot;)

    def __iter__(self) -&gt; Iterator[Any]:
        return self.get_columns().__iter__()

    def find_idx_by_name(self, name: str) -&gt; int:
        &quot;&quot;&quot;
        Find the index of a column by name.

        Parameters
        ----------
        name
            Name of the column to find.
        &quot;&quot;&quot;
        return self._df.find_idx_by_name(name)

    def _pos_idx(self, idx: int, dim: int) -&gt; int:
        if idx &gt;= 0:
            return idx
        else:
            return self.shape[dim] + idx

    def __getitem__(self, item: Any) -&gt; Any:
        &quot;&quot;&quot;
        Does quite a lot. Read the comments.
        &quot;&quot;&quot;
        if hasattr(item, &quot;_pyexpr&quot;):
            return self.select(item)
        if isinstance(item, np.ndarray):
            item = pl.Series(&quot;&quot;, item)
        # select rows and columns at once
        # every 2d selection, i.e. tuple is row column order, just like numpy
        if isinstance(item, tuple):
            row_selection, col_selection = item

            # df[:, unknown]
            if isinstance(row_selection, slice):

                # multiple slices
                # df[:, :]
                if isinstance(col_selection, slice):
                    # slice can be
                    # by index
                    #   [1:8]
                    # or by column name
                    #   [&quot;foo&quot;:&quot;bar&quot;]
                    # first we make sure that the slice is by index
                    start = col_selection.start
                    stop = col_selection.stop
                    if isinstance(col_selection.start, str):
                        start = self.find_idx_by_name(col_selection.start)
                    if isinstance(col_selection.stop, str):
                        stop = self.find_idx_by_name(col_selection.stop) + 1

                    col_selection = slice(start, stop, col_selection.step)

                    df = self.__getitem__(self.columns[col_selection])
                    return df[row_selection]

                # single slice
                # df[:, unknown]
                series = self.__getitem__(col_selection)
                # s[:]
                pl.eager.series.wrap_s(series[row_selection])

            # df[2, :] (select row as df)
            if isinstance(row_selection, int):
                if isinstance(col_selection, (slice, list, np.ndarray)):
                    df = self[:, col_selection]
                    return df.slice(row_selection, 1)
                # df[2, &quot;a&quot;]
                if isinstance(col_selection, str):
                    return self[col_selection][row_selection]

            # column selection can be &quot;a&quot; and [&quot;a&quot;, &quot;b&quot;]
            if isinstance(col_selection, str):
                col_selection = [col_selection]

            # df[:, 1]
            if isinstance(col_selection, int):
                series = self.select_at_idx(col_selection)
                return series[row_selection]

            if isinstance(col_selection, list):
                # df[:, [1, 2]]
                # select by column indexes
                if isinstance(col_selection[0], int):
                    series = [self.select_at_idx(i) for i in col_selection]
                    df = DataFrame(series)
                    return df[row_selection]
            df = self.__getitem__(col_selection)
            return df.__getitem__(row_selection)

        # select single column
        # df[&quot;foo&quot;]
        if isinstance(item, str):
            return pl.eager.series.wrap_s(self._df.column(item))

        # df[idx]
        if isinstance(item, int):
            return self.slice(self._pos_idx(item, dim=0), 1)

        # df[:]
        if isinstance(item, slice):
            if getattr(item, &quot;end&quot;, False):
                raise ValueError(&quot;A slice with steps larger than 1 is not supported.&quot;)
            if item.start is None:
                start = 0
            else:
                start = item.start
            if item.stop is None:
                stop = self.height
            else:
                stop = item.stop
            length = stop - start
            return self.slice(start, length)

        # select multiple columns
        # df[&quot;foo&quot;, &quot;bar&quot;]
        if isinstance(item, Sequence):
            if isinstance(item[0], str):
                return wrap_df(self._df.select(item))
            elif isinstance(item[0], pl.Expr):
                return self.select(item)

        # select rows by mask or index
        # df[[1, 2, 3]]
        # df[true, false, true]
        if isinstance(item, np.ndarray):
            if item.dtype == int:
                return wrap_df(self._df.take(item))
            if isinstance(item[0], str):
                return wrap_df(self._df.select(item))
        if isinstance(item, (pl.Series, Sequence)):
            if isinstance(item, Sequence):
                # only bool or integers allowed
                if type(item[0]) == bool:
                    item = pl.Series(&quot;&quot;, item)
                else:
                    return wrap_df(
                        self._df.take([self._pos_idx(i, dim=0) for i in item])
                    )
            dtype = item.dtype
            if dtype == Boolean:
                return wrap_df(self._df.filter(item.inner()))
            if dtype == UInt32:
                return wrap_df(self._df.take_with_series(item.inner()))

    def __setitem__(self, key: Union[str, int, Tuple[Any, Any]], value: Any) -&gt; None:
        # df[&quot;foo&quot;] = series
        if isinstance(key, str):
            try:
                self.replace(key, pl.Series(key, value))
            except Exception:
                self.hstack([pl.Series(key, value)], in_place=True)
        # df[idx] = series
        elif isinstance(key, int):
            assert isinstance(value, pl.Series)
            self.replace_at_idx(key, value)
        # df[a, b]
        elif isinstance(key, tuple):
            row_selection, col_selection = key
            # get series column selection
            s = self.__getitem__(col_selection)

            # dispatch to __setitem__ of Series to do modification
            s[row_selection] = value

            # now find the location to place series
            # df[idx]
            if isinstance(col_selection, int):
                self.replace_at_idx(col_selection, s)
            # df[&quot;foo&quot;]
            elif isinstance(col_selection, str):
                self.replace(col_selection, s)
        else:
            return NotImplemented

    def __len__(self) -&gt; int:
        return self.height

    def _repr_html_(self) -&gt; str:
        &quot;&quot;&quot;
        Used by jupyter notebooks to get a html table.

        Output rows and columns can be modified by setting the following ENVIRONMENT variables:

        * POLARS_FMT_MAX_COLS: set the number of columns
        * POLARS_FMT_MAX_ROWS: set the number of rows
        &quot;&quot;&quot;
        max_cols = int(os.environ.get(&quot;POLARS_FMT_MAX_COLS&quot;, default=75))
        max_rows = int(os.environ.get(&quot;POLARS_FMT_MAX_rows&quot;, 25))
        return &quot;\n&quot;.join(NotebookFormatter(self, max_cols, max_rows).render())

    def rename(self, mapping: Dict[str, str]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Rename column names.

        Parameters
        ----------
        mapping
            Key value pairs that map from old name to new name.
        &quot;&quot;&quot;
        df = self.clone()
        for k, v in mapping.items():
            df._df.rename(k, v)
        return df

    def insert_at_idx(self, index: int, series: &quot;pl.Series&quot;) -&gt; None:
        &quot;&quot;&quot;
        Insert a Series at a certain column index. This operation is in place.

        Parameters
        ----------
        index
            Column to insert the new `Series` column.
        series
            `Series` to insert.
        &quot;&quot;&quot;
        self._df.insert_at_idx(index, series._s)

    def filter(self, predicate: &quot;pl.Expr&quot;) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Filter the rows in the DataFrame based on a predicate expression.

        Parameters
        ----------
        predicate
            Expression that evaluates to a boolean Series.
        &quot;&quot;&quot;
        return (
            self.lazy()
            .filter(predicate)
            .collect(no_optimization=True, string_cache=False)
        )

    @property
    def shape(self) -&gt; Tuple[int, int]:
        &quot;&quot;&quot;
        Get the shape of the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
        &gt;&gt;&gt; dataframe.shape
        shape: (5, 1)
        ```
        &quot;&quot;&quot;
        return self._df.shape()

    @property
    def height(self) -&gt; int:
        &quot;&quot;&quot;
        Get the height of the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
        &gt;&gt;&gt; dataframe.height
        5
        ```
        &quot;&quot;&quot;
        return self._df.height()

    @property
    def width(self) -&gt; int:
        &quot;&quot;&quot;
        Get the width of the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
        &gt;&gt;&gt; dataframe.width
        1
        ```
        &quot;&quot;&quot;
        return self._df.width()

    @property
    def columns(self) -&gt; tp.List[str]:
        &quot;&quot;&quot;
        Get or set column names.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6, 7, 8],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; dataframe.columns
        ['foo', 'bar', 'ham']

        # Set column names
        &gt;&gt;&gt; dataframe.columns = ['apple', 'banana', 'orange']
        shape: (3, 3)
        ╭───────┬────────┬────────╮
        │ apple ┆ banana ┆ orange │
        │ ---   ┆ ---    ┆ ---    │
        │ i64   ┆ i64    ┆ str    │
        ╞═══════╪════════╪════════╡
        │ 1     ┆ 6      ┆ &quot;a&quot;    │
        ├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
        │ 2     ┆ 7      ┆ &quot;b&quot;    │
        ├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
        │ 3     ┆ 8      ┆ &quot;c&quot;    │
        ╰───────┴────────┴────────╯
        ```
        &quot;&quot;&quot;
        return self._df.columns()

    @columns.setter
    def columns(self, columns: tp.List[str]) -&gt; None:
        &quot;&quot;&quot;
        Change the column names of the `DataFrame`.

        Parameters
        ----------
        columns
            A list with new names for the `DataFrame`.
            The length of the list should be equal to the width of the `DataFrame`.
        &quot;&quot;&quot;
        self._df.set_column_names(columns)

    @property
    def dtypes(self) -&gt; tp.List[Type[DataType]]:
        &quot;&quot;&quot;
        Get dtypes of columns in DataFrame. Dtypes can also be found in column headers when printing the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; dataframe.dtypes
        [polars.datatypes.Int64, polars.datatypes.Float64, polars.datatypes.Utf8]
        &gt;&gt;&gt; dataframe
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ f64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 1   ┆ 6   ┆ &quot;a&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ╰─────┴─────┴─────╯
        ```
        &quot;&quot;&quot;
        return [DTYPES[idx] for idx in self._df.dtypes()]

    def describe(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Summary statistics for a DataFrame. Only summarizes numeric datatypes at the moment and returns nulls for non numeric datatypes.

        Example
        ---
        ```python
        &gt;&gt;&gt; df = pl.DataFrame({
            'a': [1.0, 2.8, 3.0],
            'b': [4, 5, 6],
            &quot;c&quot;: [True, False, True]
            })
        &gt;&gt;&gt; df.describe()
        shape: (5, 4)
        ╭──────────┬───────┬─────┬──────╮
        │ describe ┆ a     ┆ b   ┆ c    │
        │ ---      ┆ ---   ┆ --- ┆ ---  │
        │ str      ┆ f64   ┆ f64 ┆ f64  │
        ╞══════════╪═══════╪═════╪══════╡
        │ &quot;mean&quot;   ┆ 2.267 ┆ 5   ┆ null │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;std&quot;    ┆ 1.102 ┆ 1   ┆ null │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;min&quot;    ┆ 1     ┆ 4   ┆ 0.0  │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;max&quot;    ┆ 3     ┆ 6   ┆ 1    │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;median&quot; ┆ 2.8   ┆ 5   ┆ null │
        ╰──────────┴───────┴─────┴──────╯
        &quot;&quot;&quot;

        def describe_cast(self: &quot;DataFrame&quot;) -&gt; &quot;DataFrame&quot;:
            columns = []
            for s in self:
                if s.is_numeric() or s.is_boolean():
                    columns.append(s.cast(float))
                else:
                    columns.append(s)
            return pl.DataFrame(columns)

        summary = pl.functions.concat(
            [
                describe_cast(self.mean()),
                describe_cast(self.std()),
                describe_cast(self.min()),
                describe_cast(self.max()),
                describe_cast(self.median()),
            ]
        )
        summary.insert_at_idx(
            0, pl.Series(&quot;describe&quot;, [&quot;mean&quot;, &quot;std&quot;, &quot;min&quot;, &quot;max&quot;, &quot;median&quot;])
        )
        return summary

    def replace_at_idx(self, index: int, series: &quot;pl.Series&quot;) -&gt; None:
        &quot;&quot;&quot;
        Replace a column at an index location.

        Parameters
        ----------
        index
            Column index.
        series
            Series that will replace the column.
        &quot;&quot;&quot;
        self._df.replace_at_idx(index, series._s)

    def sort(
        self,
        by: Union[str, &quot;pl.Expr&quot;, tp.List[&quot;pl.Expr&quot;]],
        in_place: bool = False,
        reverse: Union[bool, tp.List[bool]] = False,
    ) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Sort the DataFrame by column.

        Parameters
        ----------
        by
            By which column to sort. Only accepts string.
        in_place
            Perform operation in-place.
        reverse
            Reverse/descending sort.

        Example
        ---
        ```python
        &gt;&gt;&gt; df = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; df.sort('foo', reverse=True)
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ f64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 1   ┆ 6   ┆ &quot;a&quot; │
        ╰─────┴─────┴─────╯
        ```

        ### Sort by multiple columns.

        For multiple columns we can also use expression syntax.

        ```python
        df.sort([col(&quot;foo&quot;), col(&quot;bar&quot;) ** 2], reverse=[True, False])
        ```
        &quot;&quot;&quot;
        if type(by) is list or isinstance(by, pl.Expr):
            df = (
                self.lazy()
                .sort(by, reverse)
                .collect(no_optimization=True, string_cache=False)
            )
            if in_place:
                self._df = df._df
                return None
            return df
        if in_place:
            self._df.sort_in_place(by, reverse)
            return None
        else:
            return wrap_df(self._df.sort(by, reverse))

    def frame_equal(self, other: &quot;DataFrame&quot;, null_equal: bool = False) -&gt; bool:
        &quot;&quot;&quot;
        Check if DataFrame is equal to other.

        Parameters
        ----------
        other
            DataFrame to compare with.
        null_equal
            Consider null values as equal.

        Example
        ---
        ```python
        &gt;&gt;&gt; df1 = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; df2 = pl.DataFrame({
            &quot;foo&quot;: [3, 2, 1],
            &quot;bar&quot;: [8.0, 7.0, 6.0],
            &quot;ham&quot;: ['c', 'b', 'a']
            })

        &gt;&gt;&gt; df1.frame_equal(df1)
        True

        &gt;&gt;&gt; df1.frame_equal(df2)
        False
        ```
        &quot;&quot;&quot;
        return self._df.frame_equal(other._df, null_equal)

    def replace(self, column: str, new_col: &quot;pl.Series&quot;) -&gt; None:
        &quot;&quot;&quot;
        Replace a column by a new Series.

        Parameters
        ----------
        column
            Column to replace.
        new_col
            New column to insert.
        &quot;&quot;&quot;
        self._df.replace(column, new_col.inner())

    def slice(self, offset: int, length: int) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Slice this DataFrame over the rows direction.

        Parameters
        ----------
        offset
            Offset index.
        length
            Length of the slice.
        &quot;&quot;&quot;
        return wrap_df(self._df.slice(offset, length))

    def limit(self, length: int = 5) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get first N rows as DataFrame.

        See Also `DataFrame.head`

        Parameters
        ----------
        length
            Amount of rows to take.
        &quot;&quot;&quot;
        return self.head(length)

    def head(self, length: int = 5) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get first N rows as DataFrame.

        Parameters
        ----------
        length
            Length of the head.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3, 4, 5],
            &quot;bar&quot;: [6, 7, 8, 9, 10],
            &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
            })

        &gt;&gt;&gt; dataframe.head(3)
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ i64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 1   ┆ 6   ┆ &quot;a&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ╰─────┴─────┴─────╯
        ```
        &quot;&quot;&quot;
        return wrap_df(self._df.head(length))

    def tail(self, length: int = 5) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get last N rows as DataFrame.

        Parameters
        ----------
        length
            Length of the tail.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3, 4, 5],
            &quot;bar&quot;: [6, 7, 8, 9, 10],
            &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
            })

        &gt;&gt;&gt; dataframe.tail(3)
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ i64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 4   ┆ 9   ┆ &quot;d&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 5   ┆ 10  ┆ &quot;e&quot; │
        ╰─────┴─────┴─────╯
        ```
        &quot;&quot;&quot;
        return wrap_df(self._df.tail(length))

    def drop_nulls(self, subset: Optional[tp.List[str]] = None) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Return a new DataFrame where the null values are dropped.
        &quot;&quot;&quot;
        if subset is not None and isinstance(subset, str):
            subset = [subset]
        return wrap_df(self._df.drop_nulls(subset))

    def pipe(self, func: Callable[..., Any], *args: Any, **kwargs: Any) -&gt; Any:
        &quot;&quot;&quot;
        Apply a function on Self.

        Parameters
        ----------
        func
            Callable.
        args
            Arguments.
        kwargs
            Keyword arguments.
        &quot;&quot;&quot;
        return func(self, *args, **kwargs)

    def groupby(self, by: Union[str, tp.List[str]]) -&gt; &quot;GroupBy&quot;:
        &quot;&quot;&quot;
        Start a groupby operation.

        Parameters
        ----------
        by
            Column(s) to group by.

        # Example

        Below we group by column `&quot;a&quot;`, and we sum column `&quot;b&quot;`.

        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {
                &quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;],
                &quot;b&quot;: [1, 2, 3, 4, 5, 6],
                &quot;c&quot;: [6, 5, 4, 3, 2, 1],
            }
        )

        assert (
            df.groupby(&quot;a&quot;)[&quot;b&quot;]
            .sum()
            .sort(by_column=&quot;a&quot;)
            .frame_equal(DataFrame({&quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &quot;&quot;: [4, 11, 6]}))
        )
        ```

        We can also loop over the grouped `DataFrame`

        ```python
        for sub_df in df.groupby(&quot;a&quot;):
            print(sub_df)
        ```
        Outputs:
        ```text
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ a   ┆ b   ┆ c   │
        │ --- ┆ --- ┆ --- │
        │ str ┆ i64 ┆ i64 │
        ╞═════╪═════╪═════╡
        │ &quot;b&quot; ┆ 2   ┆ 5   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ &quot;b&quot; ┆ 4   ┆ 3   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ &quot;b&quot; ┆ 5   ┆ 2   │
        ╰─────┴─────┴─────╯
        shape: (1, 3)
        ╭─────┬─────┬─────╮
        │ a   ┆ b   ┆ c   │
        │ --- ┆ --- ┆ --- │
        │ str ┆ i64 ┆ i64 │
        ╞═════╪═════╪═════╡
        │ &quot;c&quot; ┆ 6   ┆ 1   │
        ╰─────┴─────┴─────╯
        shape: (2, 3)
        ╭─────┬─────┬─────╮
        │ a   ┆ b   ┆ c   │
        │ --- ┆ --- ┆ --- │
        │ str ┆ i64 ┆ i64 │
        ╞═════╪═════╪═════╡
        │ &quot;a&quot; ┆ 1   ┆ 6   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ &quot;a&quot; ┆ 3   ┆ 4   │
        ╰─────┴─────┴─────╯
        ```

        &quot;&quot;&quot;
        if isinstance(by, str):
            by = [by]
        return GroupBy(self._df, by, downsample=False)

    def downsample(self, by: Union[str, tp.List[str]], rule: str, n: int) -&gt; &quot;GroupBy&quot;:
        &quot;&quot;&quot;
        Start a downsampling groupby operation.

        Parameters
        ----------
        by
            Column that will be used as key in the groupby operation.
            This should be a date64/date32 column.
        rule
            Units of the downscaling operation.

            Any of:
                - &quot;month&quot;
                - &quot;week&quot;
                - &quot;day&quot;
                - &quot;hour&quot;
                - &quot;minute&quot;
                - &quot;second&quot;

        n
            Number of units (e.g. 5 &quot;day&quot;, 15 &quot;minute&quot;.
        &quot;&quot;&quot;
        return GroupBy(self._df, by, downsample=True, rule=rule, downsample_n=n)

    def join(
        self,
        df: &quot;DataFrame&quot;,
        left_on: Optional[
            Union[str, &quot;pl.Expr&quot;, tp.List[str], tp.List[&quot;pl.Expr&quot;]]
        ] = None,
        right_on: Optional[
            Union[str, &quot;pl.Expr&quot;, tp.List[str], tp.List[&quot;pl.Expr&quot;]]
        ] = None,
        on: Optional[Union[str, tp.List[str]]] = None,
        how: str = &quot;inner&quot;,
    ) -&gt; Union[&quot;DataFrame&quot;, &quot;pl.LazyFrame&quot;]:
        &quot;&quot;&quot;
        SQL like joins.

        Parameters
        ----------
        df
            DataFrame to join with.
        left_on
            Name(s) of the left join column(s).
        right_on
            Name(s) of the right join column(s).
        on
            Name(s) of the join columns in both DataFrames.
        how
            Join strategy
                - &quot;inner&quot;
                - &quot;left&quot;
                - &quot;outer&quot;
                - &quot;asof&quot;
                - &quot;cross&quot;

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; other_dataframe = pl.DataFrame({
            &quot;apple&quot;: ['x', 'y', 'z'],
            &quot;ham&quot;: ['a', 'b', 'd']
            })

        &gt;&gt;&gt; dataframe.join(other_dataframe, on='ham')
        shape: (2, 4)
        ╭─────┬─────┬─────┬───────╮
        │ foo ┆ bar ┆ ham ┆ apple │
        │ --- ┆ --- ┆ --- ┆ ---   │
        │ i64 ┆ f64 ┆ str ┆ str   │
        ╞═════╪═════╪═════╪═══════╡
        │ 1   ┆ 6   ┆ &quot;a&quot; ┆ &quot;x&quot;   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; ┆ &quot;y&quot;   │
        ╰─────┴─────┴─────┴───────╯

        &gt;&gt;&gt; dataframe.join(other_dataframe, on='ham', how='outer')
        shape: (4, 4)
        ╭──────┬──────┬─────┬───────╮
        │ foo  ┆ bar  ┆ ham ┆ apple │
        │ ---  ┆ ---  ┆ --- ┆ ---   │
        │ i64  ┆ f64  ┆ str ┆ str   │
        ╞══════╪══════╪═════╪═══════╡
        │ 1    ┆ 6    ┆ &quot;a&quot; ┆ &quot;x&quot;   │
        ├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ 2    ┆ 7    ┆ &quot;b&quot; ┆ &quot;y&quot;   │
        ├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ null ┆ null ┆ &quot;d&quot; ┆ &quot;z&quot;   │
        ├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ 3    ┆ 8    ┆ &quot;c&quot; ┆ null  │
        ╰──────┴──────┴─────┴───────╯
        ```

        # Asof joins
        This is similar to a left-join except that we match on nearest key rather than equal keys.
        The keys must be sorted to perform an asof join

        Returns
        -------
            Joined DataFrame
        &quot;&quot;&quot;
        if how == &quot;cross&quot;:
            return wrap_df(self._df.join(df._df, [], [], how))

        left_on_: Union[tp.List[str], tp.List[pl.Expr], None]
        if isinstance(left_on, (str, pl.Expr)):
            left_on_ = [left_on]  # type: ignore[assignment]
        else:
            left_on_ = left_on

        right_on_: Union[tp.List[str], tp.List[pl.Expr], None]
        if isinstance(right_on, (str, pl.Expr)):
            right_on_ = [right_on]  # type: ignore[assignment]
        else:
            right_on_ = right_on

        if isinstance(on, str):
            left_on_ = [on]
            right_on_ = [on]
        elif isinstance(on, list):
            left_on_ = on
            right_on_ = on

        if left_on_ is None or right_on_ is None:
            raise ValueError(&quot;You should pass the column to join on as an argument.&quot;)

        if isinstance(left_on_[0], pl.Expr) or isinstance(right_on_[0], pl.Expr):
            return self.lazy().join(df.lazy(), left_on, right_on, how=how)
        else:
            return wrap_df(self._df.join(df._df, left_on_, right_on_, how))

    def apply(
        self,
        f: Callable[[Tuple[Any]], Any],
        return_dtype: Optional[Type[DataType]] = None,
    ) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Apply a custom function over the rows of the DataFrame. The rows are passed as tuple.

        Beware, this is slow.

        Parameters
        ----------
        f
            Custom function/ lambda function.
        return_dtype
            Output type of the operation. If none given, Polars tries to infer the type.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.apply(f, return_dtype))

    def with_column(self, column: Union[&quot;pl.Series&quot;, &quot;pl.Expr&quot;]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Return a new DataFrame with the column added or replaced.

        Parameters
        ----------
        column
            Series, where the name of the Series refers to the column in the DataFrame.
        &quot;&quot;&quot;
        if isinstance(column, pl.Expr):
            return self.with_columns([column])
        else:
            return wrap_df(self._df.with_column(column._s))

    def hstack(
        self, columns: Union[tp.List[&quot;pl.Series&quot;], &quot;DataFrame&quot;], in_place: bool = False
    ) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Return a new DataFrame grown horizontally by stacking multiple Series to it.

        Parameters
        ----------
        columns
            Series to stack.
        in_place
            Modify in place.
        &quot;&quot;&quot;
        if not isinstance(columns, list):
            columns = columns.get_columns()
        if in_place:
            self._df.hstack_mut([s.inner() for s in columns])
            return None
        else:
            return wrap_df(self._df.hstack([s.inner() for s in columns]))

    def vstack(self, df: &quot;DataFrame&quot;, in_place: bool = False) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Grow this DataFrame vertically by stacking a DataFrame to it.

        Parameters
        ----------
        df
            DataFrame to stack.
        in_place
            Modify in place
        &quot;&quot;&quot;
        if in_place:
            self._df.vstack_mut(df._df)
            return None
        else:
            return wrap_df(self._df.vstack(df._df))

    def drop(self, name: Union[str, tp.List[str]]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Remove column from DataFrame and return as new.

        Parameters
        ----------
        name
            Column(s) to drop.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; dataframe.drop('ham')
        shape: (3, 2)
        ╭─────┬─────╮
        │ foo ┆ bar │
        │ --- ┆ --- │
        │ i64 ┆ f64 │
        ╞═════╪═════╡
        │ 1   ┆ 6   │
        ├╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   │
        ├╌╌╌╌╌┼╌╌╌╌╌┤
        │ 3   ┆ 8   │
        ╰─────┴─────╯
        ```
        &quot;&quot;&quot;
        if isinstance(name, list):
            df = self.clone()

            for name in name:
                df._df.drop_in_place(name)
            return df

        return wrap_df(self._df.drop(name))

    def drop_in_place(self, name: str) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Drop in place.

        Parameters
        ----------
        name
            Column to drop.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.drop_in_place(name))

    def select_at_idx(self, idx: int) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Select column at index location.

        Parameters
        ----------
        idx
            Location of selection.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.select_at_idx(idx))

    def clone(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Very cheap deep clone.
        &quot;&quot;&quot;
        return wrap_df(self._df.clone())

    def get_columns(self) -&gt; tp.List[&quot;pl.Series&quot;]:
        &quot;&quot;&quot;
        Get the DataFrame as a List of Series.
        &quot;&quot;&quot;
        return list(map(lambda s: pl.eager.series.wrap_s(s), self._df.get_columns()))

    def fill_none(self, strategy: Union[str, &quot;pl.Expr&quot;]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Fill None values by a filling strategy or an Expression evaluation.

        Parameters
        ----------
        strategy
            One of:
            - &quot;backward&quot;
            - &quot;forward&quot;
            - &quot;mean&quot;
            - &quot;min'
            - &quot;max&quot;
            - &quot;zero&quot;
            - &quot;one&quot;
            Or an expression.

        Returns
        -------
            DataFrame with None replaced with the filling strategy.
        &quot;&quot;&quot;
        if isinstance(strategy, pl.Expr):
            return self.lazy().fill_none(strategy).collect()
        if not isinstance(strategy, str):
            return self.fill_none(pl.lit(strategy))
        return wrap_df(self._df.fill_none(strategy))

    def explode(self, columns: Union[str, tp.List[str]]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Explode `DataFrame` to long format by exploding a column with Lists.

        Parameters
        ----------
        columns
            Column of LargeList type.

        Returns
        -------
        DataFrame
        &quot;&quot;&quot;
        if isinstance(columns, str):
            columns = [columns]
        return wrap_df(self._df.explode(columns))

    def melt(
        self, id_vars: Union[tp.List[str], str], value_vars: Union[tp.List[str], str]
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Unpivot DataFrame to long format.

        Parameters
        ----------
        id_vars
            Columns to use as identifier variables.

        value_vars
            Values to use as identifier variables.

        Returns
        -------

        &quot;&quot;&quot;
        if isinstance(value_vars, str):
            value_vars = [value_vars]
        if isinstance(id_vars, str):
            id_vars = [id_vars]
        return wrap_df(self._df.melt(id_vars, value_vars))

    def shift(self, periods: int) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Shift the values by a given period and fill the parts that will be empty due to this operation
        with `Nones`.

        Parameters
        ----------
        periods
            Number of places to shift (may be negative).
        &quot;&quot;&quot;
        return wrap_df(self._df.shift(periods))

    def shift_and_fill(
        self, periods: int, fill_value: Union[int, str, float]
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Shift the values by a given period and fill the parts that will be empty due to this operation
        with the result of the `fill_value` expression.

        Parameters
        ----------
        periods
            Number of places to shift (may be negative).
        fill_value
            fill None values with this value.
        &quot;&quot;&quot;
        return (
            self.lazy()
            .shift_and_fill(periods, fill_value)
            .collect(no_optimization=True, string_cache=False)
        )

    def is_duplicated(self) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Get a mask of all duplicated rows in this DataFrame.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.is_duplicated())

    def is_unique(self) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Get a mask of all unique rows in this DataFrame.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.is_unique())

    def lazy(self) -&gt; &quot;pl.LazyFrame&quot;:
        &quot;&quot;&quot;
        Start a lazy query from this point. This returns a `LazyFrame` object.

        Operations on a `LazyFrame` are not executed until this is requested by either calling:

        * `.fetch()` (run on a small number of rows)
        * `.collect()` (run on all data)
        * `.describe_plan()` (print unoptimized query plan)
        * `.describe_optimized_plan()` (print optimized query plan)
        * `.show_graph()` (show (un)optimized query plan) as graphiz graph)

        Lazy operations are advised because they allow for query optimization and more parallelization.
        &quot;&quot;&quot;
        return pl.lazy.frame.wrap_ldf(self._df.lazy())

    def select(
        self, exprs: Union[str, &quot;pl.Expr&quot;, Sequence[str], Sequence[&quot;pl.Expr&quot;]]
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Select columns from this DataFrame.

        Parameters
        ----------
        exprs
            Column or columns to select.
        &quot;&quot;&quot;
        return (
            self.lazy().select(exprs).collect(no_optimization=True, string_cache=False)
        )

    def with_columns(self, exprs: Union[&quot;pl.Expr&quot;, tp.List[&quot;pl.Expr&quot;]]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Add or overwrite multiple columns in a DataFrame.

        Parameters
        ----------
        exprs
            List of Expressions that evaluate to columns.
        &quot;&quot;&quot;
        if not isinstance(exprs, list):
            exprs = [exprs]
        return (
            self.lazy()
            .with_columns(exprs)
            .collect(no_optimization=True, string_cache=False)
        )

    def n_chunks(self) -&gt; int:
        &quot;&quot;&quot;
        Get number of chunks used by the ChunkedArrays of this DataFrame.
        &quot;&quot;&quot;
        return self._df.n_chunks()

    def max(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their maximum value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.max())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hmax()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)

    def min(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their minimum value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.min())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hmin()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)

    def sum(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their sum value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.sum())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hsum()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)

    def mean(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their mean value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.mean())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hmean()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)

    def std(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their standard deviation value.
        &quot;&quot;&quot;
        return wrap_df(self._df.std())

    def var(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their variance value.
        &quot;&quot;&quot;
        return wrap_df(self._df.var())

    def median(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their median value.
        &quot;&quot;&quot;
        return wrap_df(self._df.median())

    def quantile(self, quantile: float) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their quantile value.
        &quot;&quot;&quot;
        return wrap_df(self._df.quantile(quantile))

    def to_dummies(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get one hot encoded dummy variables.
        &quot;&quot;&quot;
        return wrap_df(self._df.to_dummies())

    def drop_duplicates(
        self,
        maintain_order: bool = True,
        subset: Optional[Union[str, tp.List[str]]] = None,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Drop duplicate rows from this DataFrame.
        Note that this fails if there is a column of type `List` in the DataFrame.
        &quot;&quot;&quot;
        if subset is not None and not isinstance(subset, list):
            subset = [subset]
        return wrap_df(self._df.drop_duplicates(maintain_order, subset))

    def rechunk(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Rechunk the data in this DataFrame to a contiguous allocation.

        This will make sure all subsequent operations have optimal and predictable performance.
        &quot;&quot;&quot;
        return wrap_df(self._df.rechunk())

    def null_count(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Create a new DataFrame that shows the null counts per column.
        &quot;&quot;&quot;
        return wrap_df(self._df.null_count())

    def sample(
        self,
        n: Optional[int] = None,
        frac: Optional[float] = None,
        with_replacement: bool = False,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Sample from this DataFrame by setting either `n` or `frac`.

        Parameters
        ----------
        n
            Number of samples &lt; self.len() .
        frac
            Fraction between 0.0 and 1.0 .
        with_replacement
            Sample with replacement.
        &quot;&quot;&quot;
        if n is not None:
            return wrap_df(self._df.sample_n(n, with_replacement))
        return wrap_df(self._df.sample_frac(frac, with_replacement))

    def fold(
        self, operation: Callable[[&quot;pl.Series&quot;, &quot;pl.Series&quot;], &quot;pl.Series&quot;]
    ) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Apply a horizontal reduction on a DataFrame. This can be used to effectively
        determine aggregations on a row level, and can be applied to any DataType that
        can be supercasted (casted to a similar parent type).

        An example of the supercast rules when applying an arithmetic operation on two DataTypes are for instance:

        Int8 + Utf8 = Utf8
        Float32 + Int64 = Float32
        Float32 + Float64 = Float64

        # Examples

        ## A horizontal sum operation
        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {&quot;a&quot;: [2, 1, 3],
            &quot;b&quot;: [1, 2, 3],
            &quot;c&quot;: [1.0, 2.0, 3.0]
        })

        &gt;&gt;&gt; df.fold(lambda s1, s2: s1 + s2)
        ```
        ```text
        Series: 'a' [f64]
        [
            4
            5
            9
        ]
        ```

        ## A horizontal minimum operation

        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {&quot;a&quot;: [2, 1, 3],
            &quot;b&quot;: [1, 2, 3],
            &quot;c&quot;: [1.0, 2.0, 3.0]
        })

        &gt;&gt;&gt; df.fold(lambda s1, s2: s1.zip_with(s1 &lt; s2, s2))
        ```
        ```text
        Series: 'a' [f64]
        [
            1
            1
            3
        ]
        ```

        ## A horizontal string concattenation
        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {&quot;a&quot;: [&quot;foo&quot;, &quot;bar&quot;, 2],
            &quot;b&quot;: [1, 2, 3],
            &quot;c&quot;: [1.0, 2.0, 3.0]
        })

        &gt;&gt;&gt; df.fold(lambda s1, s2: s1 + s2)
        ```
        ```text
        Series: '' [f64]
        [
            &quot;foo11&quot;
            &quot;bar22
            &quot;233&quot;
        ]
        ```

        Parameters
        ----------
        operation
            function that takes two `Series` and returns a `Series`.
        &quot;&quot;&quot;
        if self.width == 1:
            return self.select_at_idx(0)
        df = self
        acc = operation(df.select_at_idx(0), df.select_at_idx(1))

        for i in range(2, df.width):
            acc = operation(acc, df.select_at_idx(i))
        return acc

    def row(self, index: int) -&gt; Tuple[Any]:
        &quot;&quot;&quot;
        Get a row as tuple.

        Parameters
        ----------
        index
            Row index.
        &quot;&quot;&quot;
        return self._df.row_tuple(index)

    def rows(self) -&gt; tp.List[Tuple[Any]]:
        &quot;&quot;&quot;
        Convert columnar data to rows as python tuples.
        &quot;&quot;&quot;
        return self._df.row_tuples()

    def shrink_to_fit(self, in_place: bool = False) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Shrink memory usage of this DataFrame to fit the exact capacity needed to hold the data.
        &quot;&quot;&quot;
        if in_place:
            self._df.shrink_to_fit()
            return None
        else:
            df = self.clone()
            df._df.shrink_to_fit()
            return df

    def hash_rows(
        self, k0: int = 0, k1: int = 1, k2: int = 2, k3: int = 3
    ) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Hash and combine the rows in this DataFrame.

        Hash value is UInt64

        Parameters
        ----------
        k0
            seed parameter
        k1
            seed parameter
        k2
            seed parameter
        k3
            seed parameter
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.hash_rows(k0, k1, k2, k3))
</code></pre>
<p>
</details>
</raw></p>
<h2 id="constructor"><a class="header" href="#constructor">Constructor</a></h2>
<pre><code class="language-python">DataFrame(data: OptionalUnion[Dict[str, SequenceAny], SequenceAny, np.ndarray, pd.DataFrame, pl.Series], 
    columns: OptionalSequencestr, 
    orientation: Optionalstr, 
    nullable: bool,)
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def __init__(
        self,
        data: Optional[
            Union[
                Dict[str, Sequence[Any]],
                Sequence[Any],
                np.ndarray,
                &quot;pd.DataFrame&quot;,
                &quot;pl.Series&quot;,
            ]
        ] = None,
        columns: Optional[Sequence[str]] = None,
        orientation: Optional[str] = None,
        nullable: bool = True,
    ):
        # Handle positional arguments for old constructor
        if isinstance(columns, bool):
            warnings.warn(
                &quot;Specifying nullable as a positional argument is deprecated. &quot;
                &quot;Use a keyword argument to silence this warning.&quot;,
                DeprecationWarning,
                stacklevel=2,
            )
            nullable = columns
            columns = None

        # Parse data into a list of Series
        data_series: tp.List[&quot;pl.Series&quot;]

        if data is None:
            data_series = []

        elif isinstance(data, dict):
            data_series = [
                pl.Series(k, v, nullable=nullable).inner() for k, v in data.items()
            ]

        elif isinstance(data, np.ndarray):
            shape = data.shape

            if shape == (0,):
                data_series = []

            elif len(shape) == 1:
                s = pl.Series(&quot;column_0&quot;, data, nullable=False).inner()
                data_series = [s]

            elif len(shape) == 2:
                # Infer orientation
                if orientation is None:
                    warnings.warn(
                        &quot;Default orientation for constructing DataFrame from numpy &quot;
                        'array will change from &quot;row&quot; to &quot;column&quot; in a future version. '
                        &quot;Specify orientation explicitly to silence this warning.&quot;,
                        DeprecationWarning,
                        stacklevel=2,
                    )
                    orientation = &quot;row&quot;
                # Exchange if-block above for block below when removing warning
                # if orientation is None and columns is not None:
                #     orientation = &quot;column&quot; if len(columns) == shape[0] else &quot;row&quot;

                if orientation == &quot;row&quot;:
                    data_series = [
                        pl.Series(f&quot;column_{i}&quot;, data[:, i], nullable=False).inner()
                        for i in range(shape[1])
                    ]
                else:
                    data_series = [
                        pl.Series(f&quot;column_{i}&quot;, data[i], nullable=False).inner()
                        for i in range(shape[0])
                    ]

            else:
                raise ValueError(&quot;A numpy array should have more than two dimensions.&quot;)

        elif isinstance(data, Sequence) and not isinstance(data, str):
            if len(data) == 0:
                data_series = []

            elif isinstance(data[0], pl.Series):
                data_series = []
                for i, s in enumerate(data):
                    if not s.name:  # TODO: Replace by `if s.name is None` once allowed
                        s.rename(f&quot;column_{i}&quot;, in_place=True)
                    data_series.append(s.inner())

            elif isinstance(data[0], Sequence) and not isinstance(data[0], str):
                # Infer orientation
                if orientation is None and columns is not None:
                    orientation = &quot;column&quot; if len(columns) == len(data) else &quot;row&quot;

                if orientation == &quot;row&quot;:
                    self._df = PyDataFrame.read_rows(data)
                    if columns is not None:
                        self.columns = list(columns)
                    return
                else:
                    data_series = [
                        pl.Series(f&quot;column_{i}&quot;, data[i], nullable=nullable).inner()
                        for i in range(len(data))
                    ]

            else:
                s = pl.Series(&quot;column_0&quot;, data, nullable=nullable).inner()
                data_series = [s]

        elif isinstance(data, pl.Series):
            data_series = [data.inner()]

        elif _PANDAS_AVAILABLE and isinstance(data, pd.DataFrame):
            if nullable:
                data_series = [
                    pl.Series(str(col), data[col].to_list(), nullable=True).inner()
                    for col in data.columns
                ]
            else:
                data_series = [
                    pl.Series(str(col), data[col].values, nullable=False).inner()
                    for col in data.columns
                ]

        else:
            raise ValueError(&quot;DataFrame constructor not called properly.&quot;)

        # Handle the resulting list of Series
        if not data_series and columns is not None:
            for c in columns:
                data_series.append(pl.Series(c, [], nullable=nullable).inner())

        self._df = PyDataFrame(data_series)

        if columns is not None:
            self.columns = list(columns)
</code></pre>
<p>
</details>
</raw></p>
<h2 id="methods"><a class="header" href="#methods">Methods</a></h2>
<p><div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframefrom_rows"><a class="header" href="#polarseagerframedataframefrom_rows"><code>polars.eager.frame.DataFrame.from_rows</code></a></h3>
<pre><code class="language-python">from_rows(rows: SequenceSequenceAny, 
    column_names: OptionalSequencestr, 
    column_name_mapping: OptionalDict[int, str],) -&gt; DataFrame:
</code></pre>
<p>Create a DataFrame from rows. This should only be used as a last resort, as this is more expensive than
creating from columnar data.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li></li>
<li>[<code>column_names</code>]: column names to use for the DataFrame.</li>
<li>[<code>column_name_mapping</code>]: map column index to a new name:
Example:
<pre><code class="language-python">    column_mapping: {0: &quot;first_column, 3: &quot;fourth column&quot;}
</code></pre>
</li>
</ul>
<p><strong>Decoration</strong> via <code>@staticmethod</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def from_rows(
        rows: Sequence[Sequence[Any]],
        column_names: Optional[Sequence[str]] = None,
        column_name_mapping: Optional[Dict[int, str]] = None,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Create a DataFrame from rows. This should only be used as a last resort, as this is more expensive than
        creating from columnar data.

        Parameters
        ----------
        rows
            rows.
        column_names
            column names to use for the DataFrame.
        column_name_mapping
            map column index to a new name:
            Example:
            ```python
                column_mapping: {0: &quot;first_column, 3: &quot;fourth column&quot;}
            ```
        &quot;&quot;&quot;
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_rows(rows)
        if column_names is not None:
            self.columns = list(column_names)
        if column_name_mapping is not None:
            for i, name in column_name_mapping.items():
                s = self[:, i]
                s.rename(name, in_place=True)
                self.replace_at_idx(i, s)
        return self
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeread_csv"><a class="header" href="#polarseagerframedataframeread_csv"><code>polars.eager.frame.DataFrame.read_csv</code></a></h3>
<pre><code class="language-python">read_csv(file: Union[str, BinaryIO, bytes], 
    infer_schema_length: int, 
    batch_size: int, 
    has_headers: bool, 
    ignore_errors: bool, 
    stop_after_n_rows: Optionalint, 
    skip_rows: int, 
    projection: Optionaltp.List[int], 
    sep: str, 
    columns: Optionaltp.List[str], 
    rechunk: bool, 
    encoding: str, 
    n_threads: Optionalint, 
    dtype: OptionalDict[str, TypeDataType], 
    low_memory: bool, 
    comment_char: Optionalstr, 
    null_values: OptionalUnion[str, tp.List[str], Dict[str, str]],) -&gt; DataFrame:
</code></pre>
<p>Read a CSV file into a Dataframe.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>
<p>[<code>file</code>]: Path to a file or a file like object. Any valid filepath can be used. Example: <code>file.csv</code>.</p>
</li>
<li>
<p>[<code>infer_schema_length</code>]: Maximum number of lines to read to infer schema.</p>
</li>
<li>
<p>[<code>batch_size</code>]: Number of lines to read into the buffer at once. Modify this to change performance.</p>
</li>
<li>
<p>[<code>has_headers</code>]: Indicate if first row of dataset is header or not. If set to False first row will be set to <code>column_x</code>,
<code>x</code> being an enumeration over every column in the dataset.</p>
</li>
<li>
<p>[<code>ignore_errors</code>]: Try to keep reading lines if some lines yield errors.</p>
</li>
<li>
<p>[<code>stop_after_n_rows</code>]: After n rows are read from the CSV, it stops reading.
During multi-threaded parsing, an upper bound of <code>n</code> rows
cannot be guaranteed.</p>
</li>
<li>
<p>[<code>skip_rows</code>]: Start reading after <code>skip_rows</code>.</p>
</li>
<li>
<p>[<code>projection</code>]: Indexes of columns to select. Note that column indexes count from zero.</p>
</li>
<li>
<p>[<code>sep</code>]: Character to use as delimiter in the file.</p>
</li>
<li>
<p>[<code>columns</code>]: Columns to project/ select.</p>
</li>
<li>
<p>[<code>rechunk</code>]: Make sure that all columns are contiguous in memory by aggregating the chunks into a single array.</p>
</li>
<li>
<p>[<code>encoding</code>]: Allowed encodings: <code>utf8</code>, <code>utf8-lossy</code>. Lossy means that invalid utf8 values are replaced with <code>�</code> character.</p>
</li>
<li>
<p>[<code>n_threads</code>]: Number of threads to use in csv parsing. Defaults to the number of physical cpu's of your system.</p>
</li>
<li>
<p>[<code>dtype</code>]: Overwrite the dtypes during inference.</p>
</li>
<li>
<p>[<code>low_memory</code>]: Reduce memory usage in expense of performance.</p>
</li>
<li>
<p>[<code>comment_char</code>]: character that indicates the start of a comment line, for instance '#'.</p>
</li>
<li>
<p>[<code>null_values</code>]: Values to interpret as null values. You can provide a:</p>
<ul>
<li>str -&gt; all values encountered equal to this string will be null</li>
<li>tp.List[str] -&gt; A null value per column.</li>
<li>Dict[str, str] -&gt; A dictionary that maps column name to a null value string.</li>
</ul>
</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">dataframe = pl.read_csv('file.csv', sep=';', stop_after_n_rows=25)
</code></pre>
<p><strong>Returns:</strong></p>
<p>DataFrame</p>
<p><strong>Decoration</strong> via <code>@staticmethod</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def read_csv(
        file: Union[str, BinaryIO, bytes],
        infer_schema_length: int = 100,
        batch_size: int = 64,
        has_headers: bool = True,
        ignore_errors: bool = False,
        stop_after_n_rows: Optional[int] = None,
        skip_rows: int = 0,
        projection: Optional[tp.List[int]] = None,
        sep: str = &quot;,&quot;,
        columns: Optional[tp.List[str]] = None,
        rechunk: bool = True,
        encoding: str = &quot;utf8&quot;,
        n_threads: Optional[int] = None,
        dtype: Optional[Dict[str, Type[DataType]]] = None,
        low_memory: bool = False,
        comment_char: Optional[str] = None,
        null_values: Optional[Union[str, tp.List[str], Dict[str, str]]] = None,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read a CSV file into a Dataframe.

        Parameters
        ---
        file
            Path to a file or a file like object. Any valid filepath can be used. Example: `file.csv`.
        infer_schema_length
            Maximum number of lines to read to infer schema.
        batch_size
            Number of lines to read into the buffer at once. Modify this to change performance.
        has_headers
            Indicate if first row of dataset is header or not. If set to False first row will be set to `column_x`,
            `x` being an enumeration over every column in the dataset.
        ignore_errors
            Try to keep reading lines if some lines yield errors.
        stop_after_n_rows
            After n rows are read from the CSV, it stops reading.
            During multi-threaded parsing, an upper bound of `n` rows
            cannot be guaranteed.
        skip_rows
            Start reading after `skip_rows`.
        projection
            Indexes of columns to select. Note that column indexes count from zero.
        sep
            Character to use as delimiter in the file.
        columns
            Columns to project/ select.
        rechunk
            Make sure that all columns are contiguous in memory by aggregating the chunks into a single array.
        encoding
            Allowed encodings: `utf8`, `utf8-lossy`. Lossy means that invalid utf8 values are replaced with `�` character.
        n_threads
            Number of threads to use in csv parsing. Defaults to the number of physical cpu's of your system.
        dtype
            Overwrite the dtypes during inference.
        low_memory
            Reduce memory usage in expense of performance.
        comment_char
            character that indicates the start of a comment line, for instance '#'.
        null_values
            Values to interpret as null values. You can provide a:

            - str -&gt; all values encountered equal to this string will be null
            - tp.List[str] -&gt; A null value per column.
            - Dict[str, str] -&gt; A dictionary that maps column name to a null value string.

        Example
        ---
        ```python
        dataframe = pl.read_csv('file.csv', sep=';', stop_after_n_rows=25)
        ```

        Returns
        ---
        DataFrame
        &quot;&quot;&quot;
        self = DataFrame.__new__(DataFrame)

        path: Optional[str]
        if isinstance(file, str):
            path = file
        else:
            path = None
            if isinstance(file, BytesIO):
                file = file.getvalue()
            if isinstance(file, StringIO):
                file = file.getvalue().encode()

        dtype_list: Optional[tp.List[Tuple[str, Type[DataType]]]] = None
        if dtype is not None:
            dtype_list = []
            for k, v in dtype.items():
                dtype_list.append((k, pytype_to_polars_type(v)))

        processed_null_values = _process_null_values(null_values)

        self._df = PyDataFrame.read_csv(
            file,
            infer_schema_length,
            batch_size,
            has_headers,
            ignore_errors,
            stop_after_n_rows,
            skip_rows,
            projection,
            sep,
            rechunk,
            columns,
            encoding,
            n_threads,
            path,
            dtype_list,
            low_memory,
            comment_char,
            processed_null_values,
        )
        return self
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeread_parquet"><a class="header" href="#polarseagerframedataframeread_parquet"><code>polars.eager.frame.DataFrame.read_parquet</code></a></h3>
<pre><code class="language-python">read_parquet(file: Union[str, BinaryIO], 
    stop_after_n_rows: Optionalint, 
    use_pyarrow: bool,) -&gt; DataFrame:
</code></pre>
<p>Read into a DataFrame from a parquet file.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>file</code>]: Path to a file or a file like object. Any valid filepath can be used.</li>
<li>[<code>stop_after_n_rows</code>]: Only read specified number of rows of the dataset. After <code>n</code> stops reading.</li>
<li>[<code>use_pyarrow</code>]: Use pyarrow instead of the rust native parquet reader. The pyarrow reader is more stable.</li>
</ul>
<p><strong>Decoration</strong> via <code>@staticmethod</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def read_parquet(
        file: Union[str, BinaryIO],
        stop_after_n_rows: Optional[int] = None,
        use_pyarrow: bool = False,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read into a DataFrame from a parquet file.

        Parameters
        ---
        file
            Path to a file or a file like object. Any valid filepath can be used.
        stop_after_n_rows
            Only read specified number of rows of the dataset. After `n` stops reading.
        use_pyarrow
            Use pyarrow instead of the rust native parquet reader. The pyarrow reader is more stable.
        &quot;&quot;&quot;
        if use_pyarrow:
            if stop_after_n_rows:
                raise ValueError(
                    &quot;stop_after_n_rows can not be used with 'use_pyarrow==True'.&quot;
                )
            tbl = pa.parquet.read_table(file)
            return DataFrame.from_arrow(tbl)
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_parquet(file, stop_after_n_rows)
        return self
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeread_ipc"><a class="header" href="#polarseagerframedataframeread_ipc"><code>polars.eager.frame.DataFrame.read_ipc</code></a></h3>
<pre><code class="language-python">read_ipc(file: Union[str, BinaryIO], 
    use_pyarrow: bool,) -&gt; DataFrame:
</code></pre>
<p>Read into a DataFrame from Arrow IPC stream format. This is also called the feather format.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>file</code>]: Path to a file or a file like object.</li>
<li>[<code>use_pyarrow</code>]: Use pyarrow or rust arrow backend.</li>
</ul>
<p><strong>Returns:</strong></p>
<p>DataFrame</p>
<p><strong>Decoration</strong> via <code>@staticmethod</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def read_ipc(file: Union[str, BinaryIO], use_pyarrow: bool = True) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read into a DataFrame from Arrow IPC stream format. This is also called the feather format.

        Parameters
        ----------
        file
            Path to a file or a file like object.
        use_pyarrow
            Use pyarrow or rust arrow backend.

        Returns
        -------
        DataFrame
        &quot;&quot;&quot;
        if use_pyarrow:
            tbl = pa.feather.read_table(file)
            return DataFrame.from_arrow(tbl)

        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_ipc(file)
        return self
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeread_json"><a class="header" href="#polarseagerframedataframeread_json"><code>polars.eager.frame.DataFrame.read_json</code></a></h3>
<pre><code class="language-python">read_json(file: Union[str, BytesIO]) -&gt; DataFrame:
</code></pre>
<p>Read into a DataFrame from JSON format.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>file</code>]: Path to a file or a file like object.</li>
</ul>
<p><strong>Decoration</strong> via <code>@staticmethod</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def read_json(file: Union[str, BytesIO]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Read into a DataFrame from JSON format.

        Parameters
        ----------
        file
            Path to a file or a file like object.
        &quot;&quot;&quot;
        if not isinstance(file, str):
            file = file.read().decode(&quot;utf8&quot;)
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_json(file)
        return self
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframefrom_arrow"><a class="header" href="#polarseagerframedataframefrom_arrow"><code>polars.eager.frame.DataFrame.from_arrow</code></a></h3>
<pre><code class="language-python">from_arrow(table: pa.Table, rechunk: bool) -&gt; DataFrame:
</code></pre>
<p>Create DataFrame from arrow Table.
Most will be zero copy. Types that are not supported by Polars may be cast to a closest
supported type.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>table</code>]: Arrow Table.</li>
<li>[<code>rechunk</code>]: Make sure that all data is contiguous.</li>
</ul>
<p><strong>Decoration</strong> via <code>@staticmethod</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def from_arrow(table: pa.Table, rechunk: bool = True) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Create DataFrame from arrow Table.
        Most will be zero copy. Types that are not supported by Polars may be cast to a closest
        supported type.

        Parameters
        ----------
        table
            Arrow Table.
        rechunk
            Make sure that all data is contiguous.
        &quot;&quot;&quot;
        data = {}
        for i, column in enumerate(table):
            # extract the name before casting
            if column._name is None:
                name = f&quot;column_{i}&quot;
            else:
                name = column._name

            column = coerce_arrow(column)
            data[name] = column

        table = pa.table(data)
        batches = table.to_batches()
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.from_arrow_record_batches(batches)
        if rechunk:
            return self.rechunk()
        return self
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_arrow"><a class="header" href="#polarseagerframedataframeto_arrow"><code>polars.eager.frame.DataFrame.to_arrow</code></a></h3>
<pre><code class="language-python">to_arrow() -&gt; pa.Table:
</code></pre>
<p>Collect the underlying arrow arrays in an Arrow Table.
This operation is mostly zero copy.</p>
<p>Data types that do copy:
- CategoricalType</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_arrow(self) -&gt; pa.Table:
        &quot;&quot;&quot;
        Collect the underlying arrow arrays in an Arrow Table.
        This operation is mostly zero copy.

        Data types that do copy:
            - CategoricalType
        &quot;&quot;&quot;
        record_batches = self._df.to_arrow()
        return pa.Table.from_batches(record_batches)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_json"><a class="header" href="#polarseagerframedataframeto_json"><code>polars.eager.frame.DataFrame.to_json</code></a></h3>
<pre><code class="language-python">to_json(file: OptionalUnion[BytesIO, str, Path], 
    pretty: bool, 
    to_string: bool,) -&gt; Optionalstr:
</code></pre>
<p>Serialize to JSON representation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>file</code>]: Write to this file instead of returning an string.</li>
<li>[<code>pretty</code>]: Pretty serialize json.</li>
<li>[<code>to_string</code>]: Ignore file argument and return a string.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_json(
        self,
        file: Optional[Union[BytesIO, str, Path]] = None,
        pretty: bool = False,
        to_string: bool = False,
    ) -&gt; Optional[str]:
        &quot;&quot;&quot;
        Serialize to JSON representation.

        Parameters
        ----------
        file
            Write to this file instead of returning an string.
        pretty
            Pretty serialize json.
        to_string
            Ignore file argument and return a string.
        &quot;&quot;&quot;
        if to_string:
            file = BytesIO()
            self._df.to_json(file, pretty)
            file.seek(0)
            return file.read().decode(&quot;utf8&quot;)
        else:
            self._df.to_json(file, pretty)
            return None
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_pandas"><a class="header" href="#polarseagerframedataframeto_pandas"><code>polars.eager.frame.DataFrame.to_pandas</code></a></h3>
<pre><code class="language-python">to_pandas(*args, **kwargs) -&gt; pd.DataFrame:
</code></pre>
<p>Cast to a Pandas DataFrame. This requires that Pandas is installed.
This operation clones data.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><a href="Arguments."><code>args</code></a>: Arguments will be sent to pyarrow.Table.to_pandas.</li>
<li>[<code>date_as_object</code>]: Cast dates to objects. If False, convert to datetime64[ns] dtype.</li>
<li>[<code>kwargs</code>]: Arguments will be sent to pyarrow.Table.to_pandas.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; import pandas
&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3],
    &quot;bar&quot;: [6, 7, 8],
    &quot;ham&quot;: ['a', 'b', 'c']
    })

&gt;&gt;&gt; pandas_df = dataframe.to_pandas()
&gt;&gt;&gt; type(pandas_df)
pandas.core.frame.DataFrame
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_pandas(
        self, *args: Any, date_as_object: bool = False, **kwargs: Any
    ) -&gt; &quot;pd.DataFrame&quot;:  # noqa: F821
        &quot;&quot;&quot;
        Cast to a Pandas DataFrame. This requires that Pandas is installed.
        This operation clones data.

        Parameters
        ----------
        args
            Arguments will be sent to pyarrow.Table.to_pandas.
        date_as_object
            Cast dates to objects. If False, convert to datetime64[ns] dtype.
        kwargs
            Arguments will be sent to pyarrow.Table.to_pandas.

        Example
        ---
        ```python
        &gt;&gt;&gt; import pandas
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6, 7, 8],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; pandas_df = dataframe.to_pandas()
        &gt;&gt;&gt; type(pandas_df)
        pandas.core.frame.DataFrame
        ```
        &quot;&quot;&quot;
        return self.to_arrow().to_pandas(*args, date_as_object=date_as_object, **kwargs)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_csv"><a class="header" href="#polarseagerframedataframeto_csv"><code>polars.eager.frame.DataFrame.to_csv</code></a></h3>
<pre><code class="language-python">to_csv(file: OptionalUnion[TextIO, str, Path], 
    has_headers: bool, 
    delimiter: str,) -&gt; Optionalstr:
</code></pre>
<p>Write Dataframe to comma-separated values file (csv).</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>file</code>]: File path to which the file should be written.</li>
<li>[<code>has_headers</code>]: Whether or not to include header in the CSV output.</li>
<li>[<code>delimiter</code>]: Separate CSV fields with this symbol.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3, 4, 5],
    &quot;bar&quot;: [6, 7, 8, 9, 10],
    &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
    })
&gt;&gt;&gt; dataframe.to_csv('new_file.csv', sep=',')
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_csv(
        self,
        file: Optional[Union[TextIO, str, Path]] = None,
        has_headers: bool = True,
        delimiter: str = &quot;,&quot;,
    ) -&gt; Optional[str]:
        &quot;&quot;&quot;
        Write Dataframe to comma-separated values file (csv).

        Parameters
        ---
        file
            File path to which the file should be written.
        has_headers
            Whether or not to include header in the CSV output.
        delimiter
            Separate CSV fields with this symbol.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3, 4, 5],
            &quot;bar&quot;: [6, 7, 8, 9, 10],
            &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
            })
        &gt;&gt;&gt; dataframe.to_csv('new_file.csv', sep=',')
        ```
        &quot;&quot;&quot;
        if file is None:
            buffer = BytesIO()
            self._df.to_csv(buffer, has_headers, ord(delimiter))
            return str(buffer.getvalue(), encoding=&quot;utf-8&quot;)

        if isinstance(file, Path):
            file = str(file)

        self._df.to_csv(file, has_headers, ord(delimiter))
        return None
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_ipc"><a class="header" href="#polarseagerframedataframeto_ipc"><code>polars.eager.frame.DataFrame.to_ipc</code></a></h3>
<pre><code class="language-python">to_ipc(file: Union[BinaryIO, str, Path]) -&gt; None:
</code></pre>
<p>Write to Arrow IPC binary stream, or a feather file.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>file</code>]: File path to which the file should be written.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_ipc(self, file: Union[BinaryIO, str, Path]) -&gt; None:
        &quot;&quot;&quot;
        Write to Arrow IPC binary stream, or a feather file.

        Parameters
        ----------
        file
            File path to which the file should be written.
        &quot;&quot;&quot;
        if isinstance(file, Path):
            file = str(file)

        self._df.to_ipc(file)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_parquet"><a class="header" href="#polarseagerframedataframeto_parquet"><code>polars.eager.frame.DataFrame.to_parquet</code></a></h3>
<pre><code class="language-python">to_parquet(file: Union[str, Path], 
    compression: str, 
    use_pyarrow: bool, 
    **kwargs,) -&gt; None:
</code></pre>
<p>Write the DataFrame disk in parquet format.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>file</code>]: File path to which the file should be written.</li>
<li>[<code>compression</code>]: Compression method (only supported if <code>use_pyarrow</code>).</li>
<li>[<code>use_pyarrow</code>]: Use C++ parquet implementation vs rust parquet implementation.
At the moment C++ supports more features.</li>
</ul>
<p>**kwargs are passed to pyarrow.parquet.write_table</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_parquet(
        self,
        file: Union[str, Path],
        compression: str = &quot;snappy&quot;,
        use_pyarrow: bool = True,
        **kwargs: Any,
    ) -&gt; None:
        &quot;&quot;&quot;
        Write the DataFrame disk in parquet format.

        Parameters
        ----------
        file
            File path to which the file should be written.
        compression
            Compression method (only supported if `use_pyarrow`).
        use_pyarrow
            Use C++ parquet implementation vs rust parquet implementation.
            At the moment C++ supports more features.

        **kwargs are passed to pyarrow.parquet.write_table
        &quot;&quot;&quot;
        if isinstance(file, Path):
            file = str(file)

        if use_pyarrow:
            tbl = self.to_arrow()

            data = {}

            for i, column in enumerate(tbl):
                # extract the name before casting
                if column._name is None:
                    name = f&quot;column_{i}&quot;
                else:
                    name = column._name

                # parquet casts date64 to date32 for some reason
                if column.type == pa.date64():
                    column = pa.compute.cast(column, pa.timestamp(&quot;ms&quot;, None))
                data[name] = column
            tbl = pa.table(data)

            pa.parquet.write_table(
                table=tbl, where=file, compression=compression, **kwargs
            )
        else:
            self._df.to_parquet(file)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_numpy"><a class="header" href="#polarseagerframedataframeto_numpy"><code>polars.eager.frame.DataFrame.to_numpy</code></a></h3>
<pre><code class="language-python">to_numpy() -&gt; np.ndarray:
</code></pre>
<p>Convert DataFrame to a 2d numpy array.
This operation clones data.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; import pandas
&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3],
    &quot;bar&quot;: [6, 7, 8],
    &quot;ham&quot;: ['a', 'b', 'c']
    })

&gt;&gt;&gt; numpy_array = dataframe.to_numpy()
&gt;&gt;&gt; type(numpy_array)
numpy.ndarray
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_numpy(self) -&gt; np.ndarray:
        &quot;&quot;&quot;
        Convert DataFrame to a 2d numpy array.
        This operation clones data.

        Example
        ---
        ```python
        &gt;&gt;&gt; import pandas
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6, 7, 8],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; numpy_array = dataframe.to_numpy()
        &gt;&gt;&gt; type(numpy_array)
        numpy.ndarray
        ```
        &quot;&quot;&quot;
        return np.vstack(
            [self.select_at_idx(i).to_numpy() for i in range(self.width)]
        ).T
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframefind_idx_by_name"><a class="header" href="#polarseagerframedataframefind_idx_by_name"><code>polars.eager.frame.DataFrame.find_idx_by_name</code></a></h3>
<pre><code class="language-python">find_idx_by_name(name: str) -&gt; int:
</code></pre>
<p>Find the index of a column by name.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>name</code>]: Name of the column to find.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def find_idx_by_name(self, name: str) -&gt; int:
        &quot;&quot;&quot;
        Find the index of a column by name.

        Parameters
        ----------
        name
            Name of the column to find.
        &quot;&quot;&quot;
        return self._df.find_idx_by_name(name)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframerename"><a class="header" href="#polarseagerframedataframerename"><code>polars.eager.frame.DataFrame.rename</code></a></h3>
<pre><code class="language-python">rename(mapping: Dict[str, str]) -&gt; DataFrame:
</code></pre>
<p>Rename column names.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>mapping</code>]: Key value pairs that map from old name to new name.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def rename(self, mapping: Dict[str, str]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Rename column names.

        Parameters
        ----------
        mapping
            Key value pairs that map from old name to new name.
        &quot;&quot;&quot;
        df = self.clone()
        for k, v in mapping.items():
            df._df.rename(k, v)
        return df
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeinsert_at_idx"><a class="header" href="#polarseagerframedataframeinsert_at_idx"><code>polars.eager.frame.DataFrame.insert_at_idx</code></a></h3>
<pre><code class="language-python">insert_at_idx(index: int, series: pl.Series) -&gt; None:
</code></pre>
<p>Insert a Series at a certain column index. This operation is in place.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>index</code>]: Column to insert the new <code>Series</code> column.</li>
<li>[<code>series</code>]: <code>Series</code> to insert.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def insert_at_idx(self, index: int, series: &quot;pl.Series&quot;) -&gt; None:
        &quot;&quot;&quot;
        Insert a Series at a certain column index. This operation is in place.

        Parameters
        ----------
        index
            Column to insert the new `Series` column.
        series
            `Series` to insert.
        &quot;&quot;&quot;
        self._df.insert_at_idx(index, series._s)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframefilter"><a class="header" href="#polarseagerframedataframefilter"><code>polars.eager.frame.DataFrame.filter</code></a></h3>
<pre><code class="language-python">filter(predicate: pl.Expr) -&gt; DataFrame:
</code></pre>
<p>Filter the rows in the DataFrame based on a predicate expression.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>predicate</code>]: Expression that evaluates to a boolean Series.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def filter(self, predicate: &quot;pl.Expr&quot;) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Filter the rows in the DataFrame based on a predicate expression.

        Parameters
        ----------
        predicate
            Expression that evaluates to a boolean Series.
        &quot;&quot;&quot;
        return (
            self.lazy()
            .filter(predicate)
            .collect(no_optimization=True, string_cache=False)
        )
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeshape"><a class="header" href="#polarseagerframedataframeshape"><code>polars.eager.frame.DataFrame.shape</code></a></h3>
<pre><code class="language-python">shape() -&gt; Tuple[int, int]:
</code></pre>
<p>Get the shape of the DataFrame.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
&gt;&gt;&gt; dataframe.shape
shape: (5, 1)
</code></pre>
<p><strong>Decoration</strong> via <code>@property</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def shape(self) -&gt; Tuple[int, int]:
        &quot;&quot;&quot;
        Get the shape of the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
        &gt;&gt;&gt; dataframe.shape
        shape: (5, 1)
        ```
        &quot;&quot;&quot;
        return self._df.shape()
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeheight"><a class="header" href="#polarseagerframedataframeheight"><code>polars.eager.frame.DataFrame.height</code></a></h3>
<pre><code class="language-python">height() -&gt; int:
</code></pre>
<p>Get the height of the DataFrame.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
&gt;&gt;&gt; dataframe.height
5
</code></pre>
<p><strong>Decoration</strong> via <code>@property</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def height(self) -&gt; int:
        &quot;&quot;&quot;
        Get the height of the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
        &gt;&gt;&gt; dataframe.height
        5
        ```
        &quot;&quot;&quot;
        return self._df.height()
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframewidth"><a class="header" href="#polarseagerframedataframewidth"><code>polars.eager.frame.DataFrame.width</code></a></h3>
<pre><code class="language-python">width() -&gt; int:
</code></pre>
<p>Get the width of the DataFrame.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
&gt;&gt;&gt; dataframe.width
1
</code></pre>
<p><strong>Decoration</strong> via <code>@property</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def width(self) -&gt; int:
        &quot;&quot;&quot;
        Get the width of the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({&quot;foo&quot;: [1, 2, 3, 4, 5]})
        &gt;&gt;&gt; dataframe.width
        1
        ```
        &quot;&quot;&quot;
        return self._df.width()
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframecolumns"><a class="header" href="#polarseagerframedataframecolumns"><code>polars.eager.frame.DataFrame.columns</code></a></h3>
<pre><code class="language-python">columns(columns: tp.List[str]) -&gt; None:
</code></pre>
<p>Change the column names of the <code>DataFrame</code>.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>columns</code>]: A list with new names for the <code>DataFrame</code>.
The length of the list should be equal to the width of the <code>DataFrame</code>.</li>
</ul>
<p><strong>Decoration</strong> via <code>@columns.setter</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def columns(self, columns: tp.List[str]) -&gt; None:
        &quot;&quot;&quot;
        Change the column names of the `DataFrame`.

        Parameters
        ----------
        columns
            A list with new names for the `DataFrame`.
            The length of the list should be equal to the width of the `DataFrame`.
        &quot;&quot;&quot;
        self._df.set_column_names(columns)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedtypes"><a class="header" href="#polarseagerframedataframedtypes"><code>polars.eager.frame.DataFrame.dtypes</code></a></h3>
<pre><code class="language-python">dtypes() -&gt; tp.List[TypeDataType]:
</code></pre>
<p>Get dtypes of columns in DataFrame. Dtypes can also be found in column headers when printing the DataFrame.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3],
    &quot;bar&quot;: [6.0, 7.0, 8.0],
    &quot;ham&quot;: ['a', 'b', 'c']
    })

&gt;&gt;&gt; dataframe.dtypes
[polars.datatypes.Int64, polars.datatypes.Float64, polars.datatypes.Utf8]
&gt;&gt;&gt; dataframe
shape: (3, 3)
╭─────┬─────┬─────╮
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ &quot;a&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 2   ┆ 7   ┆ &quot;b&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 3   ┆ 8   ┆ &quot;c&quot; │
╰─────┴─────┴─────╯
</code></pre>
<p><strong>Decoration</strong> via <code>@property</code>.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def dtypes(self) -&gt; tp.List[Type[DataType]]:
        &quot;&quot;&quot;
        Get dtypes of columns in DataFrame. Dtypes can also be found in column headers when printing the DataFrame.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; dataframe.dtypes
        [polars.datatypes.Int64, polars.datatypes.Float64, polars.datatypes.Utf8]
        &gt;&gt;&gt; dataframe
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ f64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 1   ┆ 6   ┆ &quot;a&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ╰─────┴─────┴─────╯
        ```
        &quot;&quot;&quot;
        return [DTYPES[idx] for idx in self._df.dtypes()]
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedescribe"><a class="header" href="#polarseagerframedataframedescribe"><code>polars.eager.frame.DataFrame.describe</code></a></h3>
<pre><code class="language-python">describe() -&gt; DataFrame:
</code></pre>
<p>Summary statistics for a DataFrame. Only summarizes numeric datatypes at the moment and returns nulls for non numeric datatypes.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; df = pl.DataFrame({
    'a': [1.0, 2.8, 3.0],
    'b': [4, 5, 6],
    &quot;c&quot;: [True, False, True]
    })
&gt;&gt;&gt; df.describe()
shape: (5, 4)
╭──────────┬───────┬─────┬──────╮
│ describe ┆ a     ┆ b   ┆ c    │
│ ---      ┆ ---   ┆ --- ┆ ---  │
│ str      ┆ f64   ┆ f64 ┆ f64  │
╞══════════╪═══════╪═════╪══════╡
│ &quot;mean&quot;   ┆ 2.267 ┆ 5   ┆ null │
├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
│ &quot;std&quot;    ┆ 1.102 ┆ 1   ┆ null │
├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
│ &quot;min&quot;    ┆ 1     ┆ 4   ┆ 0.0  │
├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
│ &quot;max&quot;    ┆ 3     ┆ 6   ┆ 1    │
├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
│ &quot;median&quot; ┆ 2.8   ┆ 5   ┆ null │
╰──────────┴───────┴─────┴──────╯




<details>
  <summary style="text-align:right">source</summary>
</raw>
```python
    def describe(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Summary statistics for a DataFrame. Only summarizes numeric datatypes at the moment and returns nulls for non numeric datatypes.

        Example
        ---
        ```python
        &gt;&gt;&gt; df = pl.DataFrame({
            'a': [1.0, 2.8, 3.0],
            'b': [4, 5, 6],
            &quot;c&quot;: [True, False, True]
            })
        &gt;&gt;&gt; df.describe()
        shape: (5, 4)
        ╭──────────┬───────┬─────┬──────╮
        │ describe ┆ a     ┆ b   ┆ c    │
        │ ---      ┆ ---   ┆ --- ┆ ---  │
        │ str      ┆ f64   ┆ f64 ┆ f64  │
        ╞══════════╪═══════╪═════╪══════╡
        │ &quot;mean&quot;   ┆ 2.267 ┆ 5   ┆ null │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;std&quot;    ┆ 1.102 ┆ 1   ┆ null │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;min&quot;    ┆ 1     ┆ 4   ┆ 0.0  │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;max&quot;    ┆ 3     ┆ 6   ┆ 1    │
        ├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┤
        │ &quot;median&quot; ┆ 2.8   ┆ 5   ┆ null │
        ╰──────────┴───────┴─────┴──────╯
        &quot;&quot;&quot;

        def describe_cast(self: &quot;DataFrame&quot;) -&gt; &quot;DataFrame&quot;:
            columns = []
            for s in self:
                if s.is_numeric() or s.is_boolean():
                    columns.append(s.cast(float))
                else:
                    columns.append(s)
            return pl.DataFrame(columns)

        summary = pl.functions.concat(
            [
                describe_cast(self.mean()),
                describe_cast(self.std()),
                describe_cast(self.min()),
                describe_cast(self.max()),
                describe_cast(self.median()),
            ]
        )
        summary.insert_at_idx(
            0, pl.Series(&quot;describe&quot;, [&quot;mean&quot;, &quot;std&quot;, &quot;min&quot;, &quot;max&quot;, &quot;median&quot;])
        )
        return summary
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedescribedescribe_cast"><a class="header" href="#polarseagerframedataframedescribedescribe_cast"><code>polars.eager.frame.DataFrame.describe.describe_cast</code></a></h3>
<pre><code class="language-python">describe_cast(: DataFrame) -&gt; DataFrame:
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">        def describe_cast(self: &quot;DataFrame&quot;) -&gt; &quot;DataFrame&quot;:
            columns = []
            for s in self:
                if s.is_numeric() or s.is_boolean():
                    columns.append(s.cast(float))
                else:
                    columns.append(s)
            return pl.DataFrame(columns)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframereplace_at_idx"><a class="header" href="#polarseagerframedataframereplace_at_idx"><code>polars.eager.frame.DataFrame.replace_at_idx</code></a></h3>
<pre><code class="language-python">replace_at_idx(index: int, series: pl.Series) -&gt; None:
</code></pre>
<p>Replace a column at an index location.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>index</code>]: Column index.</li>
<li>[<code>series</code>]: Series that will replace the column.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def replace_at_idx(self, index: int, series: &quot;pl.Series&quot;) -&gt; None:
        &quot;&quot;&quot;
        Replace a column at an index location.

        Parameters
        ----------
        index
            Column index.
        series
            Series that will replace the column.
        &quot;&quot;&quot;
        self._df.replace_at_idx(index, series._s)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframesort"><a class="header" href="#polarseagerframedataframesort"><code>polars.eager.frame.DataFrame.sort</code></a></h3>
<pre><code class="language-python">sort(by: Union[str, pl.Expr, tp.List[pl.Expr]], 
    in_place: bool, 
    reverse: Union[bool, tp.List[bool]],) -&gt; OptionalDataFrame:
</code></pre>
<p>Sort the DataFrame by column.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>by</code>]: By which column to sort. Only accepts string.</li>
<li>[<code>in_place</code>]: Perform operation in-place.</li>
<li>[<code>reverse</code>]: Reverse/descending sort.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; df = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3],
    &quot;bar&quot;: [6.0, 7.0, 8.0],
    &quot;ham&quot;: ['a', 'b', 'c']
    })

&gt;&gt;&gt; df.sort('foo', reverse=True)
shape: (3, 3)
╭─────┬─────┬─────╮
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 3   ┆ 8   ┆ &quot;c&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 2   ┆ 7   ┆ &quot;b&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 1   ┆ 6   ┆ &quot;a&quot; │
╰─────┴─────┴─────╯
</code></pre>
<h3 id="sort-by-multiple-columns"><a class="header" href="#sort-by-multiple-columns">Sort by multiple columns.</a></h3>
<p>For multiple columns we can also use expression syntax.</p>
<pre><code class="language-python">df.sort([col(&quot;foo&quot;), col(&quot;bar&quot;) ** 2], reverse=[True, False])
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def sort(
        self,
        by: Union[str, &quot;pl.Expr&quot;, tp.List[&quot;pl.Expr&quot;]],
        in_place: bool = False,
        reverse: Union[bool, tp.List[bool]] = False,
    ) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Sort the DataFrame by column.

        Parameters
        ----------
        by
            By which column to sort. Only accepts string.
        in_place
            Perform operation in-place.
        reverse
            Reverse/descending sort.

        Example
        ---
        ```python
        &gt;&gt;&gt; df = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; df.sort('foo', reverse=True)
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ f64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 1   ┆ 6   ┆ &quot;a&quot; │
        ╰─────┴─────┴─────╯
        ```

        ### Sort by multiple columns.

        For multiple columns we can also use expression syntax.

        ```python
        df.sort([col(&quot;foo&quot;), col(&quot;bar&quot;) ** 2], reverse=[True, False])
        ```
        &quot;&quot;&quot;
        if type(by) is list or isinstance(by, pl.Expr):
            df = (
                self.lazy()
                .sort(by, reverse)
                .collect(no_optimization=True, string_cache=False)
            )
            if in_place:
                self._df = df._df
                return None
            return df
        if in_place:
            self._df.sort_in_place(by, reverse)
            return None
        else:
            return wrap_df(self._df.sort(by, reverse))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeframe_equal"><a class="header" href="#polarseagerframedataframeframe_equal"><code>polars.eager.frame.DataFrame.frame_equal</code></a></h3>
<pre><code class="language-python">frame_equal(other: DataFrame, 
    null_equal: bool,) -&gt; bool:
</code></pre>
<p>Check if DataFrame is equal to other.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>other</code>]: DataFrame to compare with.</li>
<li>[<code>null_equal</code>]: Consider null values as equal.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; df1 = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3],
    &quot;bar&quot;: [6.0, 7.0, 8.0],
    &quot;ham&quot;: ['a', 'b', 'c']
    })

&gt;&gt;&gt; df2 = pl.DataFrame({
    &quot;foo&quot;: [3, 2, 1],
    &quot;bar&quot;: [8.0, 7.0, 6.0],
    &quot;ham&quot;: ['c', 'b', 'a']
    })

&gt;&gt;&gt; df1.frame_equal(df1)
True

&gt;&gt;&gt; df1.frame_equal(df2)
False
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def frame_equal(self, other: &quot;DataFrame&quot;, null_equal: bool = False) -&gt; bool:
        &quot;&quot;&quot;
        Check if DataFrame is equal to other.

        Parameters
        ----------
        other
            DataFrame to compare with.
        null_equal
            Consider null values as equal.

        Example
        ---
        ```python
        &gt;&gt;&gt; df1 = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; df2 = pl.DataFrame({
            &quot;foo&quot;: [3, 2, 1],
            &quot;bar&quot;: [8.0, 7.0, 6.0],
            &quot;ham&quot;: ['c', 'b', 'a']
            })

        &gt;&gt;&gt; df1.frame_equal(df1)
        True

        &gt;&gt;&gt; df1.frame_equal(df2)
        False
        ```
        &quot;&quot;&quot;
        return self._df.frame_equal(other._df, null_equal)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframereplace"><a class="header" href="#polarseagerframedataframereplace"><code>polars.eager.frame.DataFrame.replace</code></a></h3>
<pre><code class="language-python">replace(column: str, new_col: pl.Series) -&gt; None:
</code></pre>
<p>Replace a column by a new Series.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>column</code>]: Column to replace.</li>
<li>[<code>new_col</code>]: New column to insert.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def replace(self, column: str, new_col: &quot;pl.Series&quot;) -&gt; None:
        &quot;&quot;&quot;
        Replace a column by a new Series.

        Parameters
        ----------
        column
            Column to replace.
        new_col
            New column to insert.
        &quot;&quot;&quot;
        self._df.replace(column, new_col.inner())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeslice"><a class="header" href="#polarseagerframedataframeslice"><code>polars.eager.frame.DataFrame.slice</code></a></h3>
<pre><code class="language-python">slice(offset: int, length: int) -&gt; DataFrame:
</code></pre>
<p>Slice this DataFrame over the rows direction.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>offset</code>]: Offset index.</li>
<li>[<code>length</code>]: Length of the slice.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def slice(self, offset: int, length: int) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Slice this DataFrame over the rows direction.

        Parameters
        ----------
        offset
            Offset index.
        length
            Length of the slice.
        &quot;&quot;&quot;
        return wrap_df(self._df.slice(offset, length))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframelimit"><a class="header" href="#polarseagerframedataframelimit"><code>polars.eager.frame.DataFrame.limit</code></a></h3>
<pre><code class="language-python">limit(length: int) -&gt; DataFrame:
</code></pre>
<p>Get first N rows as DataFrame.</p>
<p>See Also <code>DataFrame.head</code></p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>length</code>]: Amount of rows to take.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def limit(self, length: int = 5) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get first N rows as DataFrame.

        See Also `DataFrame.head`

        Parameters
        ----------
        length
            Amount of rows to take.
        &quot;&quot;&quot;
        return self.head(length)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframehead"><a class="header" href="#polarseagerframedataframehead"><code>polars.eager.frame.DataFrame.head</code></a></h3>
<pre><code class="language-python">head(length: int) -&gt; DataFrame:
</code></pre>
<p>Get first N rows as DataFrame.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>length</code>]: Length of the head.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3, 4, 5],
    &quot;bar&quot;: [6, 7, 8, 9, 10],
    &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
    })

&gt;&gt;&gt; dataframe.head(3)
shape: (3, 3)
╭─────┬─────┬─────╮
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ &quot;a&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 2   ┆ 7   ┆ &quot;b&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 3   ┆ 8   ┆ &quot;c&quot; │
╰─────┴─────┴─────╯
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def head(self, length: int = 5) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get first N rows as DataFrame.

        Parameters
        ----------
        length
            Length of the head.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3, 4, 5],
            &quot;bar&quot;: [6, 7, 8, 9, 10],
            &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
            })

        &gt;&gt;&gt; dataframe.head(3)
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ i64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 1   ┆ 6   ┆ &quot;a&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ╰─────┴─────┴─────╯
        ```
        &quot;&quot;&quot;
        return wrap_df(self._df.head(length))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframetail"><a class="header" href="#polarseagerframedataframetail"><code>polars.eager.frame.DataFrame.tail</code></a></h3>
<pre><code class="language-python">tail(length: int) -&gt; DataFrame:
</code></pre>
<p>Get last N rows as DataFrame.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>length</code>]: Length of the tail.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3, 4, 5],
    &quot;bar&quot;: [6, 7, 8, 9, 10],
    &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
    })

&gt;&gt;&gt; dataframe.tail(3)
shape: (3, 3)
╭─────┬─────┬─────╮
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 3   ┆ 8   ┆ &quot;c&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 4   ┆ 9   ┆ &quot;d&quot; │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ 5   ┆ 10  ┆ &quot;e&quot; │
╰─────┴─────┴─────╯
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def tail(self, length: int = 5) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get last N rows as DataFrame.

        Parameters
        ----------
        length
            Length of the tail.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3, 4, 5],
            &quot;bar&quot;: [6, 7, 8, 9, 10],
            &quot;ham&quot;: ['a', 'b', 'c', 'd','e']
            })

        &gt;&gt;&gt; dataframe.tail(3)
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ foo ┆ bar ┆ ham │
        │ --- ┆ --- ┆ --- │
        │ i64 ┆ i64 ┆ str │
        ╞═════╪═════╪═════╡
        │ 3   ┆ 8   ┆ &quot;c&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 4   ┆ 9   ┆ &quot;d&quot; │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ 5   ┆ 10  ┆ &quot;e&quot; │
        ╰─────┴─────┴─────╯
        ```
        &quot;&quot;&quot;
        return wrap_df(self._df.tail(length))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedrop_nulls"><a class="header" href="#polarseagerframedataframedrop_nulls"><code>polars.eager.frame.DataFrame.drop_nulls</code></a></h3>
<pre><code class="language-python">drop_nulls(subset: Optionaltp.List[str]) -&gt; DataFrame:
</code></pre>
<p>Return a new DataFrame where the null values are dropped.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def drop_nulls(self, subset: Optional[tp.List[str]] = None) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Return a new DataFrame where the null values are dropped.
        &quot;&quot;&quot;
        if subset is not None and isinstance(subset, str):
            subset = [subset]
        return wrap_df(self._df.drop_nulls(subset))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframepipe"><a class="header" href="#polarseagerframedataframepipe"><code>polars.eager.frame.DataFrame.pipe</code></a></h3>
<pre><code class="language-python">pipe(func: Callable[, Any], *args, **kwargs) -&gt; Any:
</code></pre>
<p>Apply a function on Self.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li></li>
<li></li>
<li>[<code>kwargs</code>]: Keyword arguments.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def pipe(self, func: Callable[..., Any], *args: Any, **kwargs: Any) -&gt; Any:
        &quot;&quot;&quot;
        Apply a function on Self.

        Parameters
        ----------
        func
            Callable.
        args
            Arguments.
        kwargs
            Keyword arguments.
        &quot;&quot;&quot;
        return func(self, *args, **kwargs)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframegroupby"><a class="header" href="#polarseagerframedataframegroupby"><code>polars.eager.frame.DataFrame.groupby</code></a></h3>
<pre><code class="language-python">groupby(by: Union[str, tp.List[str]]) -&gt; GroupBy:
</code></pre>
<p>Start a groupby operation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>by</code>]: Column(s) to group by.</li>
</ul>
<p><strong>Example:</strong></p>
<p>Below we group by column <code>&quot;a&quot;</code>, and we sum column <code>&quot;b&quot;</code>.</p>
<pre><code class="language-python">&gt;&gt;&gt; df = pl.DataFrame(
    {
        &quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;],
        &quot;b&quot;: [1, 2, 3, 4, 5, 6],
        &quot;c&quot;: [6, 5, 4, 3, 2, 1],
    }
)

assert (
    df.groupby(&quot;a&quot;)[&quot;b&quot;]
    .sum()
    .sort(by_column=&quot;a&quot;)
    .frame_equal(DataFrame({&quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &quot;&quot;: [4, 11, 6]}))
)
</code></pre>
<p>We can also loop over the grouped <code>DataFrame</code></p>
<pre><code class="language-python">for sub_df in df.groupby(&quot;a&quot;):
    print(sub_df)
</code></pre>
<p>Outputs:</p>
<pre><code class="language-text">shape: (3, 3)
╭─────┬─────┬─────╮
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ &quot;b&quot; ┆ 2   ┆ 5   │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ &quot;b&quot; ┆ 4   ┆ 3   │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ &quot;b&quot; ┆ 5   ┆ 2   │
╰─────┴─────┴─────╯
shape: (1, 3)
╭─────┬─────┬─────╮
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ &quot;c&quot; ┆ 6   ┆ 1   │
╰─────┴─────┴─────╯
shape: (2, 3)
╭─────┬─────┬─────╮
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ &quot;a&quot; ┆ 1   ┆ 6   │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
│ &quot;a&quot; ┆ 3   ┆ 4   │
╰─────┴─────┴─────╯
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def groupby(self, by: Union[str, tp.List[str]]) -&gt; &quot;GroupBy&quot;:
        &quot;&quot;&quot;
        Start a groupby operation.

        Parameters
        ----------
        by
            Column(s) to group by.

        # Example

        Below we group by column `&quot;a&quot;`, and we sum column `&quot;b&quot;`.

        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {
                &quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;],
                &quot;b&quot;: [1, 2, 3, 4, 5, 6],
                &quot;c&quot;: [6, 5, 4, 3, 2, 1],
            }
        )

        assert (
            df.groupby(&quot;a&quot;)[&quot;b&quot;]
            .sum()
            .sort(by_column=&quot;a&quot;)
            .frame_equal(DataFrame({&quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &quot;&quot;: [4, 11, 6]}))
        )
        ```

        We can also loop over the grouped `DataFrame`

        ```python
        for sub_df in df.groupby(&quot;a&quot;):
            print(sub_df)
        ```
        Outputs:
        ```text
        shape: (3, 3)
        ╭─────┬─────┬─────╮
        │ a   ┆ b   ┆ c   │
        │ --- ┆ --- ┆ --- │
        │ str ┆ i64 ┆ i64 │
        ╞═════╪═════╪═════╡
        │ &quot;b&quot; ┆ 2   ┆ 5   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ &quot;b&quot; ┆ 4   ┆ 3   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ &quot;b&quot; ┆ 5   ┆ 2   │
        ╰─────┴─────┴─────╯
        shape: (1, 3)
        ╭─────┬─────┬─────╮
        │ a   ┆ b   ┆ c   │
        │ --- ┆ --- ┆ --- │
        │ str ┆ i64 ┆ i64 │
        ╞═════╪═════╪═════╡
        │ &quot;c&quot; ┆ 6   ┆ 1   │
        ╰─────┴─────┴─────╯
        shape: (2, 3)
        ╭─────┬─────┬─────╮
        │ a   ┆ b   ┆ c   │
        │ --- ┆ --- ┆ --- │
        │ str ┆ i64 ┆ i64 │
        ╞═════╪═════╪═════╡
        │ &quot;a&quot; ┆ 1   ┆ 6   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┤
        │ &quot;a&quot; ┆ 3   ┆ 4   │
        ╰─────┴─────┴─────╯
        ```

        &quot;&quot;&quot;
        if isinstance(by, str):
            by = [by]
        return GroupBy(self._df, by, downsample=False)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedownsample"><a class="header" href="#polarseagerframedataframedownsample"><code>polars.eager.frame.DataFrame.downsample</code></a></h3>
<pre><code class="language-python">downsample(by: Union[str, tp.List[str]], 
    rule: str, 
    n: int,) -&gt; GroupBy:
</code></pre>
<p>Start a downsampling groupby operation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>
<p>[<code>by</code>]: Column that will be used as key in the groupby operation.
This should be a date64/date32 column.</p>
</li>
<li>
<p>[<code>rule</code>]: Units of the downscaling operation.</p>
<p>Any of:
- &quot;month&quot;
- &quot;week&quot;
- &quot;day&quot;
- &quot;hour&quot;
- &quot;minute&quot;
- &quot;second&quot;</p>
</li>
<li>
<p>[<code>n</code>]: Number of units (e.g. 5 &quot;day&quot;, 15 &quot;minute&quot;.</p>
</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def downsample(self, by: Union[str, tp.List[str]], rule: str, n: int) -&gt; &quot;GroupBy&quot;:
        &quot;&quot;&quot;
        Start a downsampling groupby operation.

        Parameters
        ----------
        by
            Column that will be used as key in the groupby operation.
            This should be a date64/date32 column.
        rule
            Units of the downscaling operation.

            Any of:
                - &quot;month&quot;
                - &quot;week&quot;
                - &quot;day&quot;
                - &quot;hour&quot;
                - &quot;minute&quot;
                - &quot;second&quot;

        n
            Number of units (e.g. 5 &quot;day&quot;, 15 &quot;minute&quot;.
        &quot;&quot;&quot;
        return GroupBy(self._df, by, downsample=True, rule=rule, downsample_n=n)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframejoin"><a class="header" href="#polarseagerframedataframejoin"><code>polars.eager.frame.DataFrame.join</code></a></h3>
<pre><code class="language-python">join(df: DataFrame, 
    left_on: OptionalUnion[str, pl.Expr, tp.List[str], tp.List[pl.Expr]], 
    right_on: OptionalUnion[str, pl.Expr, tp.List[str], tp.List[pl.Expr]], 
    on: OptionalUnion[str, tp.List[str]], 
    how: str,) -&gt; Union[DataFrame, pl.LazyFrame]:
</code></pre>
<p>SQL like joins.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>df</code>]: DataFrame to join with.</li>
<li>[<code>left_on</code>]: Name(s) of the left join column(s).</li>
<li>[<code>right_on</code>]: Name(s) of the right join column(s).</li>
<li>[<code>on</code>]: Name(s) of the join columns in both DataFrames.</li>
<li>[<code>how</code>]: Join strategy
- &quot;inner&quot;
- &quot;left&quot;
- &quot;outer&quot;
- &quot;asof&quot;
- &quot;cross&quot;</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3],
    &quot;bar&quot;: [6.0, 7.0, 8.0],
    &quot;ham&quot;: ['a', 'b', 'c']
    })

&gt;&gt;&gt; other_dataframe = pl.DataFrame({
    &quot;apple&quot;: ['x', 'y', 'z'],
    &quot;ham&quot;: ['a', 'b', 'd']
    })

&gt;&gt;&gt; dataframe.join(other_dataframe, on='ham')
shape: (2, 4)
╭─────┬─────┬─────┬───────╮
│ foo ┆ bar ┆ ham ┆ apple │
│ --- ┆ --- ┆ --- ┆ ---   │
│ i64 ┆ f64 ┆ str ┆ str   │
╞═════╪═════╪═════╪═══════╡
│ 1   ┆ 6   ┆ &quot;a&quot; ┆ &quot;x&quot;   │
├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 2   ┆ 7   ┆ &quot;b&quot; ┆ &quot;y&quot;   │
╰─────┴─────┴─────┴───────╯

&gt;&gt;&gt; dataframe.join(other_dataframe, on='ham', how='outer')
shape: (4, 4)
╭──────┬──────┬─────┬───────╮
│ foo  ┆ bar  ┆ ham ┆ apple │
│ ---  ┆ ---  ┆ --- ┆ ---   │
│ i64  ┆ f64  ┆ str ┆ str   │
╞══════╪══════╪═════╪═══════╡
│ 1    ┆ 6    ┆ &quot;a&quot; ┆ &quot;x&quot;   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 2    ┆ 7    ┆ &quot;b&quot; ┆ &quot;y&quot;   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ null ┆ null ┆ &quot;d&quot; ┆ &quot;z&quot;   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 3    ┆ 8    ┆ &quot;c&quot; ┆ null  │
╰──────┴──────┴─────┴───────╯
</code></pre>
<p><strong>Asof:</strong>
joins
This is similar to a left-join except that we match on nearest key rather than equal keys.
The keys must be sorted to perform an asof join</p>
<p><strong>Returns:</strong></p>
<pre><code>Joined DataFrame
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def join(
        self,
        df: &quot;DataFrame&quot;,
        left_on: Optional[
            Union[str, &quot;pl.Expr&quot;, tp.List[str], tp.List[&quot;pl.Expr&quot;]]
        ] = None,
        right_on: Optional[
            Union[str, &quot;pl.Expr&quot;, tp.List[str], tp.List[&quot;pl.Expr&quot;]]
        ] = None,
        on: Optional[Union[str, tp.List[str]]] = None,
        how: str = &quot;inner&quot;,
    ) -&gt; Union[&quot;DataFrame&quot;, &quot;pl.LazyFrame&quot;]:
        &quot;&quot;&quot;
        SQL like joins.

        Parameters
        ----------
        df
            DataFrame to join with.
        left_on
            Name(s) of the left join column(s).
        right_on
            Name(s) of the right join column(s).
        on
            Name(s) of the join columns in both DataFrames.
        how
            Join strategy
                - &quot;inner&quot;
                - &quot;left&quot;
                - &quot;outer&quot;
                - &quot;asof&quot;
                - &quot;cross&quot;

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; other_dataframe = pl.DataFrame({
            &quot;apple&quot;: ['x', 'y', 'z'],
            &quot;ham&quot;: ['a', 'b', 'd']
            })

        &gt;&gt;&gt; dataframe.join(other_dataframe, on='ham')
        shape: (2, 4)
        ╭─────┬─────┬─────┬───────╮
        │ foo ┆ bar ┆ ham ┆ apple │
        │ --- ┆ --- ┆ --- ┆ ---   │
        │ i64 ┆ f64 ┆ str ┆ str   │
        ╞═════╪═════╪═════╪═══════╡
        │ 1   ┆ 6   ┆ &quot;a&quot; ┆ &quot;x&quot;   │
        ├╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ 2   ┆ 7   ┆ &quot;b&quot; ┆ &quot;y&quot;   │
        ╰─────┴─────┴─────┴───────╯

        &gt;&gt;&gt; dataframe.join(other_dataframe, on='ham', how='outer')
        shape: (4, 4)
        ╭──────┬──────┬─────┬───────╮
        │ foo  ┆ bar  ┆ ham ┆ apple │
        │ ---  ┆ ---  ┆ --- ┆ ---   │
        │ i64  ┆ f64  ┆ str ┆ str   │
        ╞══════╪══════╪═════╪═══════╡
        │ 1    ┆ 6    ┆ &quot;a&quot; ┆ &quot;x&quot;   │
        ├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ 2    ┆ 7    ┆ &quot;b&quot; ┆ &quot;y&quot;   │
        ├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ null ┆ null ┆ &quot;d&quot; ┆ &quot;z&quot;   │
        ├╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌┤
        │ 3    ┆ 8    ┆ &quot;c&quot; ┆ null  │
        ╰──────┴──────┴─────┴───────╯
        ```

        # Asof joins
        This is similar to a left-join except that we match on nearest key rather than equal keys.
        The keys must be sorted to perform an asof join

        Returns
        -------
            Joined DataFrame
        &quot;&quot;&quot;
        if how == &quot;cross&quot;:
            return wrap_df(self._df.join(df._df, [], [], how))

        left_on_: Union[tp.List[str], tp.List[pl.Expr], None]
        if isinstance(left_on, (str, pl.Expr)):
            left_on_ = [left_on]  # type: ignore[assignment]
        else:
            left_on_ = left_on

        right_on_: Union[tp.List[str], tp.List[pl.Expr], None]
        if isinstance(right_on, (str, pl.Expr)):
            right_on_ = [right_on]  # type: ignore[assignment]
        else:
            right_on_ = right_on

        if isinstance(on, str):
            left_on_ = [on]
            right_on_ = [on]
        elif isinstance(on, list):
            left_on_ = on
            right_on_ = on

        if left_on_ is None or right_on_ is None:
            raise ValueError(&quot;You should pass the column to join on as an argument.&quot;)

        if isinstance(left_on_[0], pl.Expr) or isinstance(right_on_[0], pl.Expr):
            return self.lazy().join(df.lazy(), left_on, right_on, how=how)
        else:
            return wrap_df(self._df.join(df._df, left_on_, right_on_, how))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeapply"><a class="header" href="#polarseagerframedataframeapply"><code>polars.eager.frame.DataFrame.apply</code></a></h3>
<pre><code class="language-python">apply(f: Callable[[TupleAny], Any], 
    return_dtype: OptionalTypeDataType,) -&gt; pl.Series:
</code></pre>
<p>Apply a custom function over the rows of the DataFrame. The rows are passed as tuple.</p>
<p>Beware, this is slow.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>f</code>]: Custom function/ lambda function.</li>
<li>[<code>return_dtype</code>]: Output type of the operation. If none given, Polars tries to infer the type.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def apply(
        self,
        f: Callable[[Tuple[Any]], Any],
        return_dtype: Optional[Type[DataType]] = None,
    ) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Apply a custom function over the rows of the DataFrame. The rows are passed as tuple.

        Beware, this is slow.

        Parameters
        ----------
        f
            Custom function/ lambda function.
        return_dtype
            Output type of the operation. If none given, Polars tries to infer the type.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.apply(f, return_dtype))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframewith_column"><a class="header" href="#polarseagerframedataframewith_column"><code>polars.eager.frame.DataFrame.with_column</code></a></h3>
<pre><code class="language-python">with_column(column: Union[pl.Series, pl.Expr],) -&gt; DataFrame:
</code></pre>
<p>Return a new DataFrame with the column added or replaced.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>column</code>]: Series, where the name of the Series refers to the column in the DataFrame.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def with_column(self, column: Union[&quot;pl.Series&quot;, &quot;pl.Expr&quot;]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Return a new DataFrame with the column added or replaced.

        Parameters
        ----------
        column
            Series, where the name of the Series refers to the column in the DataFrame.
        &quot;&quot;&quot;
        if isinstance(column, pl.Expr):
            return self.with_columns([column])
        else:
            return wrap_df(self._df.with_column(column._s))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframehstack"><a class="header" href="#polarseagerframedataframehstack"><code>polars.eager.frame.DataFrame.hstack</code></a></h3>
<pre><code class="language-python">hstack(columns: Union[tp.List[pl.Series], DataFrame], 
    in_place: bool,) -&gt; OptionalDataFrame:
</code></pre>
<p>Return a new DataFrame grown horizontally by stacking multiple Series to it.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>columns</code>]: Series to stack.</li>
<li>[<code>in_place</code>]: Modify in place.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def hstack(
        self, columns: Union[tp.List[&quot;pl.Series&quot;], &quot;DataFrame&quot;], in_place: bool = False
    ) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Return a new DataFrame grown horizontally by stacking multiple Series to it.

        Parameters
        ----------
        columns
            Series to stack.
        in_place
            Modify in place.
        &quot;&quot;&quot;
        if not isinstance(columns, list):
            columns = columns.get_columns()
        if in_place:
            self._df.hstack_mut([s.inner() for s in columns])
            return None
        else:
            return wrap_df(self._df.hstack([s.inner() for s in columns]))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframevstack"><a class="header" href="#polarseagerframedataframevstack"><code>polars.eager.frame.DataFrame.vstack</code></a></h3>
<pre><code class="language-python">vstack(df: DataFrame, 
    in_place: bool,) -&gt; OptionalDataFrame:
</code></pre>
<p>Grow this DataFrame vertically by stacking a DataFrame to it.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>df</code>]: DataFrame to stack.</li>
<li>[<code>in_place</code>]: Modify in place</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def vstack(self, df: &quot;DataFrame&quot;, in_place: bool = False) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Grow this DataFrame vertically by stacking a DataFrame to it.

        Parameters
        ----------
        df
            DataFrame to stack.
        in_place
            Modify in place
        &quot;&quot;&quot;
        if in_place:
            self._df.vstack_mut(df._df)
            return None
        else:
            return wrap_df(self._df.vstack(df._df))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedrop"><a class="header" href="#polarseagerframedataframedrop"><code>polars.eager.frame.DataFrame.drop</code></a></h3>
<pre><code class="language-python">drop(name: Union[str, tp.List[str]]) -&gt; DataFrame:
</code></pre>
<p>Remove column from DataFrame and return as new.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>name</code>]: Column(s) to drop.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">&gt;&gt;&gt; dataframe = pl.DataFrame({
    &quot;foo&quot;: [1, 2, 3],
    &quot;bar&quot;: [6.0, 7.0, 8.0],
    &quot;ham&quot;: ['a', 'b', 'c']
    })

&gt;&gt;&gt; dataframe.drop('ham')
shape: (3, 2)
╭─────┬─────╮
│ foo ┆ bar │
│ --- ┆ --- │
│ i64 ┆ f64 │
╞═════╪═════╡
│ 1   ┆ 6   │
├╌╌╌╌╌┼╌╌╌╌╌┤
│ 2   ┆ 7   │
├╌╌╌╌╌┼╌╌╌╌╌┤
│ 3   ┆ 8   │
╰─────┴─────╯
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def drop(self, name: Union[str, tp.List[str]]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Remove column from DataFrame and return as new.

        Parameters
        ----------
        name
            Column(s) to drop.

        Example
        ---
        ```python
        &gt;&gt;&gt; dataframe = pl.DataFrame({
            &quot;foo&quot;: [1, 2, 3],
            &quot;bar&quot;: [6.0, 7.0, 8.0],
            &quot;ham&quot;: ['a', 'b', 'c']
            })

        &gt;&gt;&gt; dataframe.drop('ham')
        shape: (3, 2)
        ╭─────┬─────╮
        │ foo ┆ bar │
        │ --- ┆ --- │
        │ i64 ┆ f64 │
        ╞═════╪═════╡
        │ 1   ┆ 6   │
        ├╌╌╌╌╌┼╌╌╌╌╌┤
        │ 2   ┆ 7   │
        ├╌╌╌╌╌┼╌╌╌╌╌┤
        │ 3   ┆ 8   │
        ╰─────┴─────╯
        ```
        &quot;&quot;&quot;
        if isinstance(name, list):
            df = self.clone()

            for name in name:
                df._df.drop_in_place(name)
            return df

        return wrap_df(self._df.drop(name))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedrop_in_place"><a class="header" href="#polarseagerframedataframedrop_in_place"><code>polars.eager.frame.DataFrame.drop_in_place</code></a></h3>
<pre><code class="language-python">drop_in_place(name: str) -&gt; pl.Series:
</code></pre>
<p>Drop in place.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>name</code>]: Column to drop.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def drop_in_place(self, name: str) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Drop in place.

        Parameters
        ----------
        name
            Column to drop.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.drop_in_place(name))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeselect_at_idx"><a class="header" href="#polarseagerframedataframeselect_at_idx"><code>polars.eager.frame.DataFrame.select_at_idx</code></a></h3>
<pre><code class="language-python">select_at_idx(idx: int) -&gt; pl.Series:
</code></pre>
<p>Select column at index location.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>idx</code>]: Location of selection.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def select_at_idx(self, idx: int) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Select column at index location.

        Parameters
        ----------
        idx
            Location of selection.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.select_at_idx(idx))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeclone"><a class="header" href="#polarseagerframedataframeclone"><code>polars.eager.frame.DataFrame.clone</code></a></h3>
<pre><code class="language-python">clone() -&gt; DataFrame:
</code></pre>
<p>Very cheap deep clone.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def clone(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Very cheap deep clone.
        &quot;&quot;&quot;
        return wrap_df(self._df.clone())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeget_columns"><a class="header" href="#polarseagerframedataframeget_columns"><code>polars.eager.frame.DataFrame.get_columns</code></a></h3>
<pre><code class="language-python">get_columns() -&gt; tp.List[pl.Series]:
</code></pre>
<p>Get the DataFrame as a List of Series.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def get_columns(self) -&gt; tp.List[&quot;pl.Series&quot;]:
        &quot;&quot;&quot;
        Get the DataFrame as a List of Series.
        &quot;&quot;&quot;
        return list(map(lambda s: pl.eager.series.wrap_s(s), self._df.get_columns()))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframefill_none"><a class="header" href="#polarseagerframedataframefill_none"><code>polars.eager.frame.DataFrame.fill_none</code></a></h3>
<pre><code class="language-python">fill_none(strategy: Union[str, pl.Expr]) -&gt; DataFrame:
</code></pre>
<p>Fill None values by a filling strategy or an Expression evaluation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>strategy</code>]: One of:
<ul>
<li>&quot;backward&quot;</li>
<li>&quot;forward&quot;</li>
<li>&quot;mean&quot;</li>
<li>&quot;min'</li>
<li>&quot;max&quot;</li>
<li>&quot;zero&quot;</li>
<li>&quot;one&quot;
Or an expression.</li>
</ul>
</li>
</ul>
<p><strong>Returns:</strong></p>
<pre><code>DataFrame with None replaced with the filling strategy.
</code></pre>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def fill_none(self, strategy: Union[str, &quot;pl.Expr&quot;]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Fill None values by a filling strategy or an Expression evaluation.

        Parameters
        ----------
        strategy
            One of:
            - &quot;backward&quot;
            - &quot;forward&quot;
            - &quot;mean&quot;
            - &quot;min'
            - &quot;max&quot;
            - &quot;zero&quot;
            - &quot;one&quot;
            Or an expression.

        Returns
        -------
            DataFrame with None replaced with the filling strategy.
        &quot;&quot;&quot;
        if isinstance(strategy, pl.Expr):
            return self.lazy().fill_none(strategy).collect()
        if not isinstance(strategy, str):
            return self.fill_none(pl.lit(strategy))
        return wrap_df(self._df.fill_none(strategy))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeexplode"><a class="header" href="#polarseagerframedataframeexplode"><code>polars.eager.frame.DataFrame.explode</code></a></h3>
<pre><code class="language-python">explode(columns: Union[str, tp.List[str]],) -&gt; DataFrame:
</code></pre>
<p>Explode <code>DataFrame</code> to long format by exploding a column with Lists.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>columns</code>]: Column of LargeList type.</li>
</ul>
<p><strong>Returns:</strong></p>
<p>DataFrame</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def explode(self, columns: Union[str, tp.List[str]]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Explode `DataFrame` to long format by exploding a column with Lists.

        Parameters
        ----------
        columns
            Column of LargeList type.

        Returns
        -------
        DataFrame
        &quot;&quot;&quot;
        if isinstance(columns, str):
            columns = [columns]
        return wrap_df(self._df.explode(columns))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframemelt"><a class="header" href="#polarseagerframedataframemelt"><code>polars.eager.frame.DataFrame.melt</code></a></h3>
<pre><code class="language-python">melt(id_vars: Union[tp.List[str], str], 
    value_vars: Union[tp.List[str], str],) -&gt; DataFrame:
</code></pre>
<p>Unpivot DataFrame to long format.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>
<p>[<code>id_vars</code>]: Columns to use as identifier variables.</p>
</li>
<li>
<p>[<code>value_vars</code>]: Values to use as identifier variables.</p>
</li>
</ul>
<p><strong>Returns:</strong></p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def melt(
        self, id_vars: Union[tp.List[str], str], value_vars: Union[tp.List[str], str]
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Unpivot DataFrame to long format.

        Parameters
        ----------
        id_vars
            Columns to use as identifier variables.

        value_vars
            Values to use as identifier variables.

        Returns
        -------

        &quot;&quot;&quot;
        if isinstance(value_vars, str):
            value_vars = [value_vars]
        if isinstance(id_vars, str):
            id_vars = [id_vars]
        return wrap_df(self._df.melt(id_vars, value_vars))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeshift"><a class="header" href="#polarseagerframedataframeshift"><code>polars.eager.frame.DataFrame.shift</code></a></h3>
<pre><code class="language-python">shift(periods: int) -&gt; DataFrame:
</code></pre>
<p>Shift the values by a given period and fill the parts that will be empty due to this operation
with <code>Nones</code>.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>periods</code>]: Number of places to shift (may be negative).</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def shift(self, periods: int) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Shift the values by a given period and fill the parts that will be empty due to this operation
        with `Nones`.

        Parameters
        ----------
        periods
            Number of places to shift (may be negative).
        &quot;&quot;&quot;
        return wrap_df(self._df.shift(periods))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeshift_and_fill"><a class="header" href="#polarseagerframedataframeshift_and_fill"><code>polars.eager.frame.DataFrame.shift_and_fill</code></a></h3>
<pre><code class="language-python">shift_and_fill(periods: int, 
    fill_value: Union[int, str, float],) -&gt; DataFrame:
</code></pre>
<p>Shift the values by a given period and fill the parts that will be empty due to this operation
with the result of the <code>fill_value</code> expression.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>periods</code>]: Number of places to shift (may be negative).</li>
<li>[<code>fill_value</code>]: fill None values with this value.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def shift_and_fill(
        self, periods: int, fill_value: Union[int, str, float]
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Shift the values by a given period and fill the parts that will be empty due to this operation
        with the result of the `fill_value` expression.

        Parameters
        ----------
        periods
            Number of places to shift (may be negative).
        fill_value
            fill None values with this value.
        &quot;&quot;&quot;
        return (
            self.lazy()
            .shift_and_fill(periods, fill_value)
            .collect(no_optimization=True, string_cache=False)
        )
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeis_duplicated"><a class="header" href="#polarseagerframedataframeis_duplicated"><code>polars.eager.frame.DataFrame.is_duplicated</code></a></h3>
<pre><code class="language-python">is_duplicated() -&gt; pl.Series:
</code></pre>
<p>Get a mask of all duplicated rows in this DataFrame.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def is_duplicated(self) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Get a mask of all duplicated rows in this DataFrame.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.is_duplicated())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeis_unique"><a class="header" href="#polarseagerframedataframeis_unique"><code>polars.eager.frame.DataFrame.is_unique</code></a></h3>
<pre><code class="language-python">is_unique() -&gt; pl.Series:
</code></pre>
<p>Get a mask of all unique rows in this DataFrame.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def is_unique(self) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Get a mask of all unique rows in this DataFrame.
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.is_unique())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframelazy"><a class="header" href="#polarseagerframedataframelazy"><code>polars.eager.frame.DataFrame.lazy</code></a></h3>
<pre><code class="language-python">lazy() -&gt; pl.LazyFrame:
</code></pre>
<p>Start a lazy query from this point. This returns a <code>LazyFrame</code> object.</p>
<p>Operations on a <code>LazyFrame</code> are not executed until this is requested by either calling:</p>
<ul>
<li><code>.fetch()</code> (run on a small number of rows)</li>
<li><code>.collect()</code> (run on all data)</li>
<li><code>.describe_plan()</code> (print unoptimized query plan)</li>
<li><code>.describe_optimized_plan()</code> (print optimized query plan)</li>
<li><code>.show_graph()</code> (show (un)optimized query plan) as graphiz graph)</li>
</ul>
<p>Lazy operations are advised because they allow for query optimization and more parallelization.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def lazy(self) -&gt; &quot;pl.LazyFrame&quot;:
        &quot;&quot;&quot;
        Start a lazy query from this point. This returns a `LazyFrame` object.

        Operations on a `LazyFrame` are not executed until this is requested by either calling:

        * `.fetch()` (run on a small number of rows)
        * `.collect()` (run on all data)
        * `.describe_plan()` (print unoptimized query plan)
        * `.describe_optimized_plan()` (print optimized query plan)
        * `.show_graph()` (show (un)optimized query plan) as graphiz graph)

        Lazy operations are advised because they allow for query optimization and more parallelization.
        &quot;&quot;&quot;
        return pl.lazy.frame.wrap_ldf(self._df.lazy())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeselect"><a class="header" href="#polarseagerframedataframeselect"><code>polars.eager.frame.DataFrame.select</code></a></h3>
<pre><code class="language-python">select(exprs: Union[str, pl.Expr, Sequencestr, Sequencepl.Expr],) -&gt; DataFrame:
</code></pre>
<p>Select columns from this DataFrame.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>exprs</code>]: Column or columns to select.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def select(
        self, exprs: Union[str, &quot;pl.Expr&quot;, Sequence[str], Sequence[&quot;pl.Expr&quot;]]
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Select columns from this DataFrame.

        Parameters
        ----------
        exprs
            Column or columns to select.
        &quot;&quot;&quot;
        return (
            self.lazy().select(exprs).collect(no_optimization=True, string_cache=False)
        )
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframewith_columns"><a class="header" href="#polarseagerframedataframewith_columns"><code>polars.eager.frame.DataFrame.with_columns</code></a></h3>
<pre><code class="language-python">with_columns(exprs: Union[pl.Expr, tp.List[pl.Expr]],) -&gt; DataFrame:
</code></pre>
<p>Add or overwrite multiple columns in a DataFrame.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>exprs</code>]: List of Expressions that evaluate to columns.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def with_columns(self, exprs: Union[&quot;pl.Expr&quot;, tp.List[&quot;pl.Expr&quot;]]) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Add or overwrite multiple columns in a DataFrame.

        Parameters
        ----------
        exprs
            List of Expressions that evaluate to columns.
        &quot;&quot;&quot;
        if not isinstance(exprs, list):
            exprs = [exprs]
        return (
            self.lazy()
            .with_columns(exprs)
            .collect(no_optimization=True, string_cache=False)
        )
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframen_chunks"><a class="header" href="#polarseagerframedataframen_chunks"><code>polars.eager.frame.DataFrame.n_chunks</code></a></h3>
<pre><code class="language-python">n_chunks() -&gt; int:
</code></pre>
<p>Get number of chunks used by the ChunkedArrays of this DataFrame.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def n_chunks(self) -&gt; int:
        &quot;&quot;&quot;
        Get number of chunks used by the ChunkedArrays of this DataFrame.
        &quot;&quot;&quot;
        return self._df.n_chunks()
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframemax"><a class="header" href="#polarseagerframedataframemax"><code>polars.eager.frame.DataFrame.max</code></a></h3>
<pre><code class="language-python">max(axis: int) -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their maximum value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def max(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their maximum value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.max())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hmax()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframemin"><a class="header" href="#polarseagerframedataframemin"><code>polars.eager.frame.DataFrame.min</code></a></h3>
<pre><code class="language-python">min(axis: int) -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their minimum value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def min(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their minimum value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.min())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hmin()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframesum"><a class="header" href="#polarseagerframedataframesum"><code>polars.eager.frame.DataFrame.sum</code></a></h3>
<pre><code class="language-python">sum(axis: int) -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their sum value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def sum(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their sum value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.sum())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hsum()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframemean"><a class="header" href="#polarseagerframedataframemean"><code>polars.eager.frame.DataFrame.mean</code></a></h3>
<pre><code class="language-python">mean(axis: int) -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their mean value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def mean(self, axis: int = 0) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their mean value.
        &quot;&quot;&quot;
        if axis == 0:
            return wrap_df(self._df.mean())
        if axis == 1:
            return pl.eager.series.wrap_s(self._df.hmean()).to_frame()
        raise ValueError(&quot;Axis should be 0 or 1.&quot;)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframestd"><a class="header" href="#polarseagerframedataframestd"><code>polars.eager.frame.DataFrame.std</code></a></h3>
<pre><code class="language-python">std() -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their standard deviation value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def std(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their standard deviation value.
        &quot;&quot;&quot;
        return wrap_df(self._df.std())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframevar"><a class="header" href="#polarseagerframedataframevar"><code>polars.eager.frame.DataFrame.var</code></a></h3>
<pre><code class="language-python">var() -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their variance value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def var(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their variance value.
        &quot;&quot;&quot;
        return wrap_df(self._df.var())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframemedian"><a class="header" href="#polarseagerframedataframemedian"><code>polars.eager.frame.DataFrame.median</code></a></h3>
<pre><code class="language-python">median() -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their median value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def median(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their median value.
        &quot;&quot;&quot;
        return wrap_df(self._df.median())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframequantile"><a class="header" href="#polarseagerframedataframequantile"><code>polars.eager.frame.DataFrame.quantile</code></a></h3>
<pre><code class="language-python">quantile(quantile: float) -&gt; DataFrame:
</code></pre>
<p>Aggregate the columns of this DataFrame to their quantile value.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def quantile(self, quantile: float) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Aggregate the columns of this DataFrame to their quantile value.
        &quot;&quot;&quot;
        return wrap_df(self._df.quantile(quantile))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeto_dummies"><a class="header" href="#polarseagerframedataframeto_dummies"><code>polars.eager.frame.DataFrame.to_dummies</code></a></h3>
<pre><code class="language-python">to_dummies() -&gt; DataFrame:
</code></pre>
<p>Get one hot encoded dummy variables.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def to_dummies(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Get one hot encoded dummy variables.
        &quot;&quot;&quot;
        return wrap_df(self._df.to_dummies())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframedrop_duplicates"><a class="header" href="#polarseagerframedataframedrop_duplicates"><code>polars.eager.frame.DataFrame.drop_duplicates</code></a></h3>
<pre><code class="language-python">drop_duplicates(maintain_order: bool, 
    subset: OptionalUnion[str, tp.List[str]],) -&gt; DataFrame:
</code></pre>
<p>Drop duplicate rows from this DataFrame.
Note that this fails if there is a column of type <code>List</code> in the DataFrame.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def drop_duplicates(
        self,
        maintain_order: bool = True,
        subset: Optional[Union[str, tp.List[str]]] = None,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Drop duplicate rows from this DataFrame.
        Note that this fails if there is a column of type `List` in the DataFrame.
        &quot;&quot;&quot;
        if subset is not None and not isinstance(subset, list):
            subset = [subset]
        return wrap_df(self._df.drop_duplicates(maintain_order, subset))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframerechunk"><a class="header" href="#polarseagerframedataframerechunk"><code>polars.eager.frame.DataFrame.rechunk</code></a></h3>
<pre><code class="language-python">rechunk() -&gt; DataFrame:
</code></pre>
<p>Rechunk the data in this DataFrame to a contiguous allocation.</p>
<p>This will make sure all subsequent operations have optimal and predictable performance.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def rechunk(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Rechunk the data in this DataFrame to a contiguous allocation.

        This will make sure all subsequent operations have optimal and predictable performance.
        &quot;&quot;&quot;
        return wrap_df(self._df.rechunk())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframenull_count"><a class="header" href="#polarseagerframedataframenull_count"><code>polars.eager.frame.DataFrame.null_count</code></a></h3>
<pre><code class="language-python">null_count() -&gt; DataFrame:
</code></pre>
<p>Create a new DataFrame that shows the null counts per column.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def null_count(self) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Create a new DataFrame that shows the null counts per column.
        &quot;&quot;&quot;
        return wrap_df(self._df.null_count())
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframesample"><a class="header" href="#polarseagerframedataframesample"><code>polars.eager.frame.DataFrame.sample</code></a></h3>
<pre><code class="language-python">sample(n: Optionalint, 
    frac: Optionalfloat, 
    with_replacement: bool,) -&gt; DataFrame:
</code></pre>
<p>Sample from this DataFrame by setting either <code>n</code> or <code>frac</code>.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>n</code>]: Number of samples &lt; self.len() .</li>
<li>[<code>frac</code>]: Fraction between 0.0 and 1.0 .</li>
<li>[<code>with_replacement</code>]: Sample with replacement.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def sample(
        self,
        n: Optional[int] = None,
        frac: Optional[float] = None,
        with_replacement: bool = False,
    ) -&gt; &quot;DataFrame&quot;:
        &quot;&quot;&quot;
        Sample from this DataFrame by setting either `n` or `frac`.

        Parameters
        ----------
        n
            Number of samples &lt; self.len() .
        frac
            Fraction between 0.0 and 1.0 .
        with_replacement
            Sample with replacement.
        &quot;&quot;&quot;
        if n is not None:
            return wrap_df(self._df.sample_n(n, with_replacement))
        return wrap_df(self._df.sample_frac(frac, with_replacement))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframefold"><a class="header" href="#polarseagerframedataframefold"><code>polars.eager.frame.DataFrame.fold</code></a></h3>
<pre><code class="language-python">fold(operation: Callable[[pl.Series, pl.Series], pl.Series],) -&gt; pl.Series:
</code></pre>
<p>Apply a horizontal reduction on a DataFrame. This can be used to effectively
determine aggregations on a row level, and can be applied to any DataType that
can be supercasted (casted to a similar parent type).</p>
<p>An example of the supercast rules when applying an arithmetic operation on two DataTypes are for instance:</p>
<p>Int8 + Utf8 = Utf8
Float32 + Int64 = Float32
Float32 + Float64 = Float64</p>
<p><strong>Examples:</strong></p>
<h2 id="a-horizontal-sum-operation"><a class="header" href="#a-horizontal-sum-operation">A horizontal sum operation</a></h2>
<pre><code class="language-python">&gt;&gt;&gt; df = pl.DataFrame(
    {&quot;a&quot;: [2, 1, 3],
    &quot;b&quot;: [1, 2, 3],
    &quot;c&quot;: [1.0, 2.0, 3.0]
})

&gt;&gt;&gt; df.fold(lambda s1, s2: s1 + s2)
</code></pre>
<pre><code class="language-text">Series: 'a' [f64]
[
    4
    5
    9
]
</code></pre>
<h2 id="a-horizontal-minimum-operation"><a class="header" href="#a-horizontal-minimum-operation">A horizontal minimum operation</a></h2>
<pre><code class="language-python">&gt;&gt;&gt; df = pl.DataFrame(
    {&quot;a&quot;: [2, 1, 3],
    &quot;b&quot;: [1, 2, 3],
    &quot;c&quot;: [1.0, 2.0, 3.0]
})

&gt;&gt;&gt; df.fold(lambda s1, s2: s1.zip_with(s1 &lt; s2, s2))
</code></pre>
<pre><code class="language-text">Series: 'a' [f64]
[
    1
    1
    3
]
</code></pre>
<h2 id="a-horizontal-string-concattenation"><a class="header" href="#a-horizontal-string-concattenation">A horizontal string concattenation</a></h2>
<pre><code class="language-python">&gt;&gt;&gt; df = pl.DataFrame(
    {&quot;a&quot;: [&quot;foo&quot;, &quot;bar&quot;, 2],
    &quot;b&quot;: [1, 2, 3],
    &quot;c&quot;: [1.0, 2.0, 3.0]
})

&gt;&gt;&gt; df.fold(lambda s1, s2: s1 + s2)
</code></pre>
<pre><code class="language-text">Series: '' [f64]
[
    &quot;foo11&quot;
    &quot;bar22
    &quot;233&quot;
]
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>operation</code>]: function that takes two <code>Series</code> and returns a <code>Series</code>.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def fold(
        self, operation: Callable[[&quot;pl.Series&quot;, &quot;pl.Series&quot;], &quot;pl.Series&quot;]
    ) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Apply a horizontal reduction on a DataFrame. This can be used to effectively
        determine aggregations on a row level, and can be applied to any DataType that
        can be supercasted (casted to a similar parent type).

        An example of the supercast rules when applying an arithmetic operation on two DataTypes are for instance:

        Int8 + Utf8 = Utf8
        Float32 + Int64 = Float32
        Float32 + Float64 = Float64

        # Examples

        ## A horizontal sum operation
        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {&quot;a&quot;: [2, 1, 3],
            &quot;b&quot;: [1, 2, 3],
            &quot;c&quot;: [1.0, 2.0, 3.0]
        })

        &gt;&gt;&gt; df.fold(lambda s1, s2: s1 + s2)
        ```
        ```text
        Series: 'a' [f64]
        [
            4
            5
            9
        ]
        ```

        ## A horizontal minimum operation

        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {&quot;a&quot;: [2, 1, 3],
            &quot;b&quot;: [1, 2, 3],
            &quot;c&quot;: [1.0, 2.0, 3.0]
        })

        &gt;&gt;&gt; df.fold(lambda s1, s2: s1.zip_with(s1 &lt; s2, s2))
        ```
        ```text
        Series: 'a' [f64]
        [
            1
            1
            3
        ]
        ```

        ## A horizontal string concattenation
        ```python
        &gt;&gt;&gt; df = pl.DataFrame(
            {&quot;a&quot;: [&quot;foo&quot;, &quot;bar&quot;, 2],
            &quot;b&quot;: [1, 2, 3],
            &quot;c&quot;: [1.0, 2.0, 3.0]
        })

        &gt;&gt;&gt; df.fold(lambda s1, s2: s1 + s2)
        ```
        ```text
        Series: '' [f64]
        [
            &quot;foo11&quot;
            &quot;bar22
            &quot;233&quot;
        ]
        ```

        Parameters
        ----------
        operation
            function that takes two `Series` and returns a `Series`.
        &quot;&quot;&quot;
        if self.width == 1:
            return self.select_at_idx(0)
        df = self
        acc = operation(df.select_at_idx(0), df.select_at_idx(1))

        for i in range(2, df.width):
            acc = operation(acc, df.select_at_idx(i))
        return acc
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframerow"><a class="header" href="#polarseagerframedataframerow"><code>polars.eager.frame.DataFrame.row</code></a></h3>
<pre><code class="language-python">row(index: int) -&gt; TupleAny:
</code></pre>
<p>Get a row as tuple.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>index</code>]: Row index.</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def row(self, index: int) -&gt; Tuple[Any]:
        &quot;&quot;&quot;
        Get a row as tuple.

        Parameters
        ----------
        index
            Row index.
        &quot;&quot;&quot;
        return self._df.row_tuple(index)
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframerows"><a class="header" href="#polarseagerframedataframerows"><code>polars.eager.frame.DataFrame.rows</code></a></h3>
<pre><code class="language-python">rows() -&gt; tp.List[TupleAny]:
</code></pre>
<p>Convert columnar data to rows as python tuples.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def rows(self) -&gt; tp.List[Tuple[Any]]:
        &quot;&quot;&quot;
        Convert columnar data to rows as python tuples.
        &quot;&quot;&quot;
        return self._df.row_tuples()
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframeshrink_to_fit"><a class="header" href="#polarseagerframedataframeshrink_to_fit"><code>polars.eager.frame.DataFrame.shrink_to_fit</code></a></h3>
<pre><code class="language-python">shrink_to_fit(in_place: bool) -&gt; OptionalDataFrame:
</code></pre>
<p>Shrink memory usage of this DataFrame to fit the exact capacity needed to hold the data.</p>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def shrink_to_fit(self, in_place: bool = False) -&gt; Optional[&quot;DataFrame&quot;]:
        &quot;&quot;&quot;
        Shrink memory usage of this DataFrame to fit the exact capacity needed to hold the data.
        &quot;&quot;&quot;
        if in_place:
            self._df.shrink_to_fit()
            return None
        else:
            df = self.clone()
            df._df.shrink_to_fit()
            return df
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
<div class='function-wrap'></raw></p>
<h3 id="polarseagerframedataframehash_rows"><a class="header" href="#polarseagerframedataframehash_rows"><code>polars.eager.frame.DataFrame.hash_rows</code></a></h3>
<pre><code class="language-python">hash_rows(k0: int, 
    k1: int, 
    k2: int, 
    k3: int,) -&gt; pl.Series:
</code></pre>
<p>Hash and combine the rows in this DataFrame.</p>
<p>Hash value is UInt64</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>[<code>k0</code>]: seed parameter</li>
<li>[<code>k1</code>]: seed parameter</li>
<li>[<code>k2</code>]: seed parameter</li>
<li>[<code>k3</code>]: seed parameter</li>
</ul>
<p>
<details>
  <summary style="text-align:right">source</summary>
</raw></p>
<pre><code class="language-python">    def hash_rows(
        self, k0: int = 0, k1: int = 1, k2: int = 2, k3: int = 3
    ) -&gt; &quot;pl.Series&quot;:
        &quot;&quot;&quot;
        Hash and combine the rows in this DataFrame.

        Hash value is UInt64

        Parameters
        ----------
        k0
            seed parameter
        k1
            seed parameter
        k2
            seed parameter
        k3
            seed parameter
        &quot;&quot;&quot;
        return pl.eager.series.wrap_s(self._df.hash_rows(k0, k1, k2, k3))
</code></pre>
<p>
</details>
</raw></p>
<p></div></raw>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../../../polars/eager/frame.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="../../../polars/eager/frame/GroupBy.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../../../polars/eager/frame.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="../../../polars/eager/frame/GroupBy.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="../../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="../../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
        <script type="text/javascript" src="../../../theme/js/index.js"></script>
        

        

    </body>
</html>
